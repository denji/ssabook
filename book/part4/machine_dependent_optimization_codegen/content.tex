\chapter{Introduction \Author{B. Dupont de Dinechin}}
\inputprogress
\label{chap:ssa-codegen}

In a compiler for imperative languages like C, C++, or Fortran, the code
generator covers the set of code transformations and optimizations that operate
on a program representation close to the target processor ISA, and produce an
assembly source or relocatable file with debugging information as result.

The main duties of code generation are: lowering the program intermediate
representation to the target processor instruction and calling conventions;
allocating variable live ranges to architectural registers; scheduling
instructions to exploit micro-architecture; and producing assembly source or
object code.

Precisely, in the 1986 edition of
the ``Compilers Principles, Techniques, and Tools'' Dragon Book by Aho et al.,
the tasks of code generation are listed as:
\begin{itemize}
\item Instruction selection and calling conventions lowering.
\item Control-flow (dominators, loops) and data-flow (variable liveness) analyses.
\item Register allocation and stack frame building.
\item Peephole optimizations.
\end{itemize}
Ten years later, the 1997 textbook ``Advanced Compiler Design \& Implementation''
by Muchnich extends code generation with the following: \begin{itemize}
\item Loop unrolling and basic block replication.
\item Instruction scheduling and software pipelining.
\item Branch optimizations and basic block alignment.
\end{itemize}
In recent releases of compilers such as the Open64 or GCC, code generation
techniques have significantly evolved, as they are mainly responsible for
exploiting the performance-oriented features of processor architectures and
micro-architectures. Code generation techniques implement in these compilers
include: \begin{itemize}
\item If-conversion using conditional MOVE, SELECT, or predicated, instructions.
\item Use of specialized addressing modes such as auto-modified and modulo.
\item Exploitation of hardware looping instruction or static branch prediction
hints.
\item Matching fixed-point arithmetic and SIMD idioms by special instructions.
\item Memory hierarchy optimizations, including pre-fetching and pre-loading
data.
\item Bundling of VLIW instructions, that may interact with instruction
scheduling.
\end{itemize}

This increasing sophistication of compiler code generation techniques motivates
the introduction of the SSA-form in order to simplify analyses and
optimizations. However, using the SSA form on machine instructions raises issues,
a number of wich we list in Section~\ref{sec:ssa-codegen-issues} issues.
Moreover, the applicability of the SSA form only spans the phases that appear
early in the code generation process: from instruction selection, down to
register allocation. After register allocation, program variables are mapped to
architectural registers or to memory locations, so the SSA form analyses and
optimizations no longer apply. The suitability of the SSA form for several code
generation phases is discussed in
Section~\ref{sec:ssa-codegen-suitability}. Finally, engineering a code generator
with the SSA form as a first class representation presents several options
presented in Section~\ref{sec:ssa-codegen-engineering}.

\section{Issues of the SSA form on machine instructions}
\label{sec:ssa-codegen-issues}.

\subsection{Un-splittable critical edges}

In compiler code generator, the sequential layout of basic blocks is a
structural component of the program representation, is the target of specific
optimizations, and is constrained by several factors, including exception
handling ranges in compilers such as the Open64. A number of embedded processor
architectures such as the Tensilica Xtensa provide hardware loops, where an
implicit conditional branch back to the loop header is taken whenever the
program counter match some address. A number of SSA form optimizations require
that critical edges be split, however this is not possible with hardware loop
back edges.

\subsection{Instructions with multiple target operands}

Machine instructions may have multiple target operands, such as memory
accesses with auto-modified addressing, or memory loads into register pairs.
More generally, instructions with a register tuple target operand such as long
multiplies of the ARM imply multiple results as far as the SSA form is
concerned, whether on the instruction itself, or on a pseudo-instruction
instructions that extracts the individual components of the register tuple. So
there is no longer a one-to-one mapping between variable definitions and
instructions for the SSA form on machine instructions.

\subsection{Special processor registers}

The SSA form analyses and optimizations assumes that variable definitions
are kills. As discussed earlier, this is not the case for condition registers
with sticky bit semantics. Besides sticky bits, any containment or overlap
between bit-fields abstracted as SSA variables, such as the condition codes of
the processor status register, implies aliasing between these variables that
must be worked around so their definition can be processed as kills.

\subsection{Stack pointer register}

Some variables, such as the stack pointer, must be bound to a specific
register at all points in the program, for instance if interrupt handlers reuse
the program run-time stack. One possibility for such case is to inhibit the
promotion of the stack pointer variable to a SSA variable. As a result, all
instructions that use the stack pointer must be specialized with respect to
their semantics as far as the SSA form optimizations are concerned.

\subsection{ISA and ABI operand constraints}

Machine instruction operands may be constrained to specific architectural
registers, either by the instruction set architecture (ISA constraints), or by
the run-time software conventions such as the application binary interface (ABI
constraints). One way to deal with this problem is by inserting parallel COPY
instruction that write to the constrained source operands or read from the constrained
target operands of the instructions. The new SSA variables thus created are pre-colored
with the required architectural register. The parallel COPY instructions are
coalesced away or sequentialized when going out of SSA.

\subsection{Must be same / different operand constraints}

Machine instruction operands may be constrained to use the same
architectural register between a source and a target operand, or even to use
different architectural registers between two source operands (MUL
instructions on the ARM). Operand constraints between one source and the
target operand are the general case on popular instruction set architectures such as
x68 and the ARM~Thumb. These constraints are represented by inserting a COPY
between the constrained source operand and a new variable, then using this new
variable as the constrained source operand. The COPY is a parallel copy in case of
multiple constrained source operands. Again, the COPY instructions are processed when
going out of SSA.

\subsection{Predicated instructions}

Predicated instructions present another aspect of definitions that do not
kill the target register. Extensions such as $\psi$-SSA
(Chapter~\ref{chap:psi_ssa}) specifically address the issues of handling
predicated instructions in the SSA form. A simpler solution is as follows: for
each target operand of the predicated instruction, add a corresponding source
operand in the instruction signature; then add an operand renaming constraint
between the target operands and the corresponding source operands. This simple
transformation enables SSA form analyses and optimizations to remain oblivious
to predicated instructions; for instance, a conditional MOVE appears as a SELECT
instruction. The drawback of this solution is that predicated definitions of a
given variable (before SSA renaming) remain in dominance order across
transformations, as opposed to $\psi$-SSA where predicate analysis may enable to
relax this order.


\section{Suitability of the SSA to code generation phases}
\label{sec:ssa-codegen-suitability}

\begin{itemize}

\item Analyses such as induction variable classification, bit-width analysis,
variable interference, liveness sets, and liveness checking
(Chapter~\ref{chap:liveness_analysis}).

\item Instruction selection (Chapter~\ref{chapter:code_selection}). Unlike
classic techniques that match one IR tree or one DAG at a time, using the SSA
form as input extends the scope of pattern matching to more complex IR graphs,
in particular those resulting from control-flow constructs.

\item If-conversion or instruction predication
(Chapter~\ref{chap:if_conversion}). A predicated instruction behavior includes a
traditional data processing part such as arithmetic or memory access, and a
predicate evaluation part often connected to a separate operand. When the
predicate evaluates to false, the instruction has no architectural effects. The
simplest form of predicated instruction is the conditional MOVE such as
CMOV\emph{xx} instructions on the x86. 

\item Inner loop unrolling or unwinding. Non-inner loop transformations, such as
unroll-and-jam, are usually left to the IR loop optimizer. Loop unrolling
replicates the loop body and removes all but one of the replicated loop exit
branches. Loop unwinding replicates the loop body while keeping the loop exit
branches. This style of loop unrolling necessarily applies to counted loops, and
requires that pre-conditioning or post-conditioning code be inserted
\cite{Lownet:1992:JS}. Inner loop unrolling or unwinding is facilitated by using
the loop-closed SSA form (Chapter~\ref{chap19:loopTree}), the SSA version of the
self assignment technique also pioneered by the Multiflow Trace Scheduling
compiler \cite{Lownet:1992:JS}.

\item Memory addressing and memory packing optimizations. Memory addressing
optimizations include selection of auto-modified addressing modes. Memory
packing optimizations select wider memory access instructions whenever the
effective addresses are provably adjacent, and no side effects such as
possible address misalignment traps are introduced.

\item Constant propagation, copy folding, and dead code elimination.

\item Instruction re-selection. Uses bit width analysis.

\end{itemize} \medskip

Further down the code generator, the next major phase is pre-pass instruction
scheduling. Innermost loops with a single basic block or super block body are
candidates for software pipelining techniques such as modulo scheduling. For
innermost loops that are not software pipelined, and for other program regions,
acyclic instruction scheduling techniques apply: basic block scheduling;
super-block scheduling; hyper-block scheduling; tree block scheduling; or trace
scheduling.

By definition, pre-pass instruction scheduling operates before register
allocation. On a classic code generator, instruction operands are mostly virtual
registers, except for instructions with ISA or ABI constraints that binds them
to specific architectural registers. Moreover, preparation to pre-pass
instruction scheduling include virtual register renaming, also known as register
web construction, in order to reduce the number of anti dependences and output
dependences in the instruction scheduling problem. Other reasons why it seems
there is little to gain to schedule instructions on a SSA form program
representation include: \begin{itemize}

\item Except in case of trace scheduling, the scheduling regions considered
earlier are single-entry and do not have control-flow merge. So there are no
$\phi$-functions in case of acyclic scheduling, and only $\phi$-functions in the
loop header in case of software pipelining. Keeping those $\phi$-functions in
the scheduling problem has no benefits and raises engineering issues, due to
their parallel execution semantics and the constraint to keep them first in
basic blocks.

\item Instruction scheduling must account for all the instruction issue slots
required to execute a code region. If the only ordering constraints between
instructions, besides control dependences and memory dependences, are limited to
true data dependences on operands, code motion will create interferences that
must later be resolved by inserting COPY instruction in the scheduled code
region. (Except for interferences created by the overlapping of live ranges
that results from modulo scheduling, as these are resolved by modulo renaming.)
So scheduling instructions with SSA variables as operands is not effective
unless extra dependences are added to the scheduling problem to prevent such
code motion. 

\item Machine instructions may have side effects on stateful resources such as
the processor condition codes. Representing them as SSA variables even though
they are not operated like the processor architectural registers requires
special casing. For instance, 'sticky' flags definitions of the IEEE~754
arithmetic imply a OR with the previous value. All such definitions can be
reordered with regards to the next use, and an instruction scheduler is expected
to do so. The SSA form on machine instructions ordered by def-use on variables
do not expose this flexibility.

\item Move effects around COPY(ies) 

\end{itemize} These issues need to be addressed before any pre-pass instruction
scheduling on the SSA form demonstrates advantages over classic approaches.
\medskip

The last major phase of code generation where SSA form has demonstrated benefits
is register allocation and its three sub-problems: variable spilling, variable
coloring, and variable coalescing (Chapter~\ref{chap:register_allocation}).

\section{Engineering a SSA form code generator}
\label{sec:ssa-codegen-engineering}

\begin{itemize}

\item Machine description system

\item Choices of phi function semantics

\item Register allocate under SSA or not

\item Keep conventional SSA everywhere

\item SSA on stack slots for register allocation

\end{itemize}

% Control structures Bourdoncle Havlak.

% Choice to keep conventional or not.

% Choice to use multiplex or not

% Choice to use DJ graph or not

% Reassociation under SSA

% Hardware loop pseudo instructions

% Maximum coalescing before instruction scheduling (dedicated etc.)

% SSA operation parameters versus instruction operands: implicit operands.

% Loop nesting forest for abstract interpretation (under SSA)


%\section{Interference graphs on the SSA form}

%that enabling information such as pointer aliasing and memory dependence be
%available. The main stand-alone SSA-based analyses useful in a code generator
%are induction variable classification, and liveness analysis. Other

%Code generation techniques have significantly evolved in the past decades, as
%they are mainly responsible for exploiting increasingly sophisticated processor
%architectures and micro-architectures. Features to be addressed
%by the code generator include: selection of SIMD instructions; selection of
%conditional moves or predicated instructions; exploitation of hardware looping
%or branch prediction hints; exploitation of DSP-like addressing modes
%such as auto-modified; explicit memory hierarchy control, including pre-fetching
%of pre-loading data; exploitation of wide instruction issuing and instruction pipelining
%through instruction scheduling and

