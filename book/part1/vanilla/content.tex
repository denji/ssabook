%% \chapter{Introduction \Author{J. Singer}\\\progressbar[0.4\textwidth]{draft}{70}}
\chapter{Introduction \Author{J. Singer}}


%%%%%%%%%%%

% Possibility of unique names for distinct entities.
% Maybe a slightly humorous example, involving Homer Simpson and
% Homer the classical Greek poet. Convey the point that,
% without unique names, extra \textit{context} is required
% to make the name useful.
% (Springfield or Greece?)

In computer programming, as in real life, 
names are useful handles for concrete entities.
% Discuss the utility of names as abstract identifiers.
The key message of this book is that
having \textit{unique names} for
\textit{distinct entities}
reduces uncertainty and imprecision.

For example, consider overhearing a conversation
about `Homer.' Without any more contextual clues, you
cannot disambiguate between Homer Simpson and Homer the
classical Greek poet; or indeed, any other people
called Homer that you may know.
As soon as the conversation mentions Springfield
(rather than Smyrna), you are fairly sure that the
Simpsons television series (rather than Greek poetry)
is the subject.
On the other hand, if everyone had a \textit{unique} name,
then there would be no possibility of confusing 20th century
American cartoon characters with ancient Greek literary figures.
\textit{Could we have a cartoon picture here?}

% where SSA is applied, in compiler intermediate representations...
This book is about the \textit{static single assignment form} (SSA),
which is a naming convention for storage locations (variables)
in low-level representations
of computer programs.
%% remove following definition, since we have a full Section
%% on definition coming up soon...
% A program is said to be in SSA form when each variable is defined (hence
% \textit{assignment})
% exactly once (hence \textit{single}) in the program text
% (hence \textit{static}).
The term \textit{static} indicates that SSA is particularly
relevant for program analysis that occurs prior to execution.
The term \textit{single} refers to the uniqueness property of
variable names that SSA imposes. As illustrated above, this enables
more accurate analysis.
The term \textit{assignment} means variable definitions. For
instance, in the code 
\begin{verbatim}
x := y+1
\end{verbatim}
the variable $x$ is being assigned the value of expression $(y+1)$.
This is a definition, or assignment, of $x$.

%%%%%%%%%%%%%%%%%%%%%

\section{Definition of SSA}


The seminal paper on SSA 
\cite{cytron91efficiently}
gives an informal prose
definition as follows:

\begin{quotation}
A program is defined to be in SSA
form if each variable is a target of
exactly one assignment statement in the
program text.
\end{quotation}

% Informally, static means `program text.'
% single means `unique names'
% assignment means `at variable definitions.'

%% Again, informally, unique definition for each variable.

This is the simplest,
least constrained, definition of SSA. However
there are various, more specialized, varieties of SSA,
which impose further constraints on programs.
Such constraints are generally expressed in terms
of dominance properties of variable definitions, or
the presence or absence of certain 
pseudo-functions at control-flow merge points.
% Formally, in terms of dominance. Each var has a unique
% definition, and def dominates all uses.
% Perhaps require implicit defs of all vars at entry,
% implicit uses of all vars at exit?
Each distinct SSA flavour has specific properties---many of
these are discussed in Chapter \ref{FIXME} 2.
% forward links to Philip's discussion of
% SSA flavours and properties here

One important property that holds for all forms of SSA,
including the simple definition above, is 
\emph{referential transparency}.
Since there is only a single definition for each variable
in the program text, a variable's value
is independent of
its position in the program.
(We may refine the information we have for a variable
based on branching conditions, but the underlying value
does not change at an \texttt{if} statement.)
Programs written in pure functional languages
are referentially transparent.

Referentially transparent programs are more amenable to 
formal methods and mathematical reasoning since
the meaning of an expression depends only on the
meaning of its subexpressions
and not on the order of evaluation or
side-effects of other expressions.

For a referentially opaque program, consider
the following program fragment.
\begin{verbatim}
x := 1;
y := x + 1;
x := 2;
z := x + 1;
\end{verbatim}
A naive (and incorrect) analysis may assume that the values
of y and z are equivalent, since they have identical 
assignments of $(x+1)$. 
However the value of variable $x$ depends on whether
the current code position is before or after the second assignment
to $x$. 

When this program fragment is transformed to SSA code,
it becomes referentially transparent. The translation process
involves renaming to  
eliminate multiple assignments to the same variable. Now it is
apparent that $y$ and $z$ are only equivalent if $x1$ and $x2$
are equivalent.
\begin{verbatim}
x1 := 1;
y  := x1 + 1;
x2 := 2;
z  := x2 + 1;
\end{verbatim}


% "The most important feature of mathematical notation is that an expression is used solely to describe (or denote) a value. In other words, the meaning of an expression is its value and there are no other effects, hidden or otherwise, in any procedure for actually obtaining it. Furthermore, the value of an expression depends only on the values of its constituent expressions (if any) and these subexpressions may be replaced freely by others possessing the same value. ... The characteristic property of mathematical expressions described here is called "referential transparency." Bird, Richard, and Wadler, Philip; Introduction to Functional Programming, p. 4; Prentice Hall, 1988.


%%%%%%%%%%%%%%%%%%%%%



\section{Informal Semantics of SSA}

% including examples


In the previous section, we saw how straightline sequences of code
can be transformed to SSA by simple renaming of variable definitions.
The \textit{target} of the definition is the variable being defined, on the
left-hand side of the assignment statement.
In SSA, each definition target must be a unique variable name.
On the other hand, variable names can be used multiple times
on the right-hand side of any assignment statements, as 
\textit{source} variables for definitions.
Throughout this book, renaming is generally performed by 
adding integer subscripts to original variable names;
however in general this is an unimportant implementation feature.

% Given a simple pseudo-code language, show examples of programs in SSA.
% (Should I show before/after SSA transformation, or just programs
% in SSA form already? Fabrice suggests before/after... plus
% one or two sentences commentary on each.)

The \textit{$\phi$-function} is the most important SSA concept to grasp.
%% (Explain carefully how $\phi$-functions work.) 
It is a special statement, known as a
\textit{pseudo-assignment} function.
Appel \cite{appel97modern} calls it as a `notational fiction.'
The purpose of a $\phi$-function is to merge
values from different incoming paths, at control-flow
merge points.

Consider the following example:

\begin{verbatim}
x := input();
if (x == 42)
    y := 1;
else
    y := x*2;
print(y);
\end{verbatim}

There is a distinct definition of $y$ in each branch of the \texttt{if}
statement. So multiple definitions of $y$ reach the \texttt{print} statement
at the control-flow merge point. When this program is transformed to SSA,
the multiple definitions of $y$ are renamed as $y1$ and $y2$. However 
the \texttt{print} statement could use either variable, dependent on the
outcome of the \texttt{if} conditional test. A $\phi$-function introduces
a new variable $y3$, which takes the value of either $y1$ or $y2$.
Thus the SSA version of the program is:

\begin{verbatim}
x := input();
if (x == 42)
    y1 := 1;
else
    y2 := x*2;
y3 := \phi(y1,y2);
print(y);
\end{verbatim}



At the start of a block of code, the $\phi$-function has
$n$ parameters if there are $n$ incoming control-flow paths to this block.
The behaviour of the $\phi$-function is to select the value
of the parameter associated with the actually executed control-flow path.
This value is assigned to the fresh variable name, on the left-hand-side
of the $\phi$-function.
Such pseudo-functions are required to maintain the SSA property
of unique variable definitions,
in the presence of non-sequential control flow.

\textit{FIXME - I'm worried about the order of information
presented in these paragraphs. I think it all needs to be there,
but maybe it could be organized more intuitively... -jsinger}

It is important to note that, if there are multiple $\phi$-functions
at the head of a basic block, then these are executed simultaneously,
\textit{not} sequentially.
This distinction becomes important if the target of a $\phi$-function
is the same as the source of another $\phi$-function, perhaps after
optimizations such as copy propagation. \textit{(ref later chapters?)}

Strictly speaking, $\phi$-functions are not directly executable,
since the dynamic control-flow path leading to the $\phi$-function
is not explicitly encoded as an input to $\phi$-function.
This is tolerable, since $\phi$-functions are only 
used during static analysis of the program. They are removed
before any program interpretation or execution takes place.
There are various executable extensions of $\phi$-functions, 
such as $\gamma$-functions, which take
an extra parameter to specify which source value to assign to the
target variable. (forward ref to VSDG chapter?)

When we eliminate $\phi$-functions in the SSA destruction phase,
they are replaced by parallel copy operations at the end of predecessor
control flow nodes. (forward note to Fabrice's section on this,
in later chapter).

(Perhaps put in a footnote about how $\phi$-functions were
called \textit{phoney}-functions at IBM during the development
of SSA - as reported by Kenny Zadeck.)
example 3. while loop? (iteration)

\textit{FIXME - I would like an example of how to transform a 
while loop into SSA, showing how the $\phi$-function
must be placed at the loop header. Fabrice doesn't think this
example is necessary, but it would be helpful for beginners, I feel...
-jsinger}

\begin{verbatim}
x = 0;
y = 0;
while (x< 10) {
  y = y + x;
  x++;
}
print(y)
\end{verbatim}



%%%%%%%%%%%


%%%%%%%%%%%

\section{Comparison with Classical Data Flow Analysis}

\textit{FIXME - still need to redraft this section...}

Very simple. Discuss lattice-based data flow analysis.
Propagating facts around control-flow points in a CFG.

Talk about SSA simplification - rename whenever data flow
facts can change (for a certain class of data flow problems?)
so, can associate facts directly with names, rather than with
name at point.
Plain SSA - rename at variable definitions - so any data flow
analysis where data flow properties change only with definitions
(e.g. constant propagation) OK. Other data flow properties may 
change at other points - can still fit these neatly into the SSA
analysis framework by inserting additional pseudo-definitions
to rename variables. examples? (forward pointers).


%%%%%%%%%%%%%%%%

\section{SSA in Context}


% Crib most of this from Kenneth Zadeck. 

% Talk about other program dependence graph
% representations, 

\subsection{Historical Context}

Throughout the 1980s, various compiler intermediate
representations (IRs) were proposed to encapsulate data
dependence, in a way that enabled fast and accurate
data flow analysis.
The key property that motivated the design of
such IRs was the exposure of variable \textit{def-use} 
information, giving the ability
to propagate data flow information directly
from definitions to uses,
and vice versa.
Example IRs include the program dependence graph \cite{ferrante87program}
and program dependence web \cite{ottenstein90program}.
Chapter \ref{vsdg} VSDG? gives further details on dependencegraph
style IRs.

% Talk about early developments at IBM in 1980s.
% Talk about eventual emergence of SSA.

Static single assignment form was one such IR, 
which was developed at IBM Research, and publicly announced
in several research papers in the late 1980s
\cite{rosen88global,alpern88detecting,cytron89efficient}.
SSA rapidly gained popularity due to its 
intuitive nature and straightforward
construction algorithm.
The single assignment constraint gives a 
standardized shape for variable def-use chains,
which can simplify data flow analysis techniques.

\subsection{Current Usage}

The majority of current commercial and open-source compilers
use SSA as a key intermediate representation for
program analysis.
SSA is generally enabled with the \texttt{-O}
flag in ahead-of-time compilers (since SSA construction
is fairly expensive, and only required for optimization).
Again, for just-in-time compilers, only the \textit{hot} 
methods will be recompiled with SSA-based optimizations.

All modern optimizing compiler infrastructures, e.g.\ LLVM, 
use SSA from the ground up.
Other compilers, e.g.\ GCC, began
development before SSA was well-characterized or
widely known.
In such cases, SSA support can be backported into 
the original optimization infrastructure.
For instance, GCC uses SSA as of version 4.0
\cite{novillo03tree,novillo04design}.
\textit{perhaps give forward pointer to Diego's chapter on the advantages
of SSA in gcc?}

\subsection{SSA for High-Level Languages}

So far, we have presented SSA as a useful feature for 
compiler-based analysis of low-level programs.
It is interesting to note that some high-level languages enforce
the SSA property.
The SISAL language is defined in such a way that
programs automatically have referential transparency, since
multiple assignments are not permitted to variables.
Other languages allow the single assignment property to be
applied on a per-variable basis, using facilities like
Java \texttt{final} variables
and C\# \texttt{const} and \texttt{readonly} modifiers. 

The motivation for allowing the programmer to enforce
SSA in an explicit manner in high-level programs is that
\textit{immutability simplifies concurrent programming}.
Read-only data can be shared freely between multiple threads,
without any data dependence problems.
This is becoming an increasingly important issue, with the
trend of multi- and many-core processors.

Chapter \ref{} \textit{intro-semantics} details the correspondence
between SSA and functional programming.
In brief, referential transparency is one of the
cornerstones of the functional programming paradigm, so 
functional languages support single assignment by default.

% However in general,
% it is straightforward to translate a non-SSA program into an SSA
% program. (Links to appropriate chapters here?
% Simple construction / Advanced construction chapters.)



%%%%%%%%%%%%%%%%

\section{Benefits of SSA}

In this chapter, we have introduced the notion of SSA.
We now conclude by enumerating some of the benefits it provides.

SSA imposes a strict discipline on the variable naming in programs,
in such a way that each variable has a unique definition point.
New names are introduced at variable assignments, and at control-flow
merge points.
This serves to simplify variable def-use relationships,
which underpin data flow analysis.
There are three main advantages that SSA enables:
\begin{description}
\item[Program runtime benefit]
Certain compiler optimizations can be more effective
when operating on programs in SSA form. These include the
class of \textit{control-flow insensitive analyses}.
\item[Compile time benefit]
Certain compiler optimizations can be more efficient
when operating on SSA programs, since
referential transparency means that data flow information
can be associated directly with variables, rather than with variables
at each program point.
\item[Compiler development benefit]
Program analyses and transformations can be easier
to express in SSA. This means that compiler engineers
can be more productive, in writing new compiler passes,
and debugging existing passes.
\texttt{FIXME - Any anecdotal experience from GCC - ask Diego?}
\end{description}



%%%%%%%%%%%
