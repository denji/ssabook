% vim:spell:spelllang=en:textwidth=0

\chapter{SSA Reconstruction \Author{S. Hack}}
\label{chapter:repair_maintain_ssa_after_optimization}
\inputpath{part1}{repair_maintain_ssa_after_optimization}
\inputprogress

{
\def\pendphi{pending\_$\phi$\xspace}
%Here the currssadir is \currentssadir.

\section{Introduction}

Some optimizations break the single-assignment property of the SSA form by inserting additional definitions for a single SSA value.
A common example is live-range splitting by inserting copy operations or inserting spill and reload code during register allocation.
Other optimizations, such as loop unrolling or jump threading, might duplicate code, thus adding additional variable definitions, \emph{and} modify the control flow of the program.
We will first go through two examples before we present algorithms to properly repair SSA.

\subsection{Live-Range Splitting}

The first example is depicted in Figure~\ref{fig:ex1}.
Our spilling pass decided to spill a part of the live range of variable $x_0$
in the right block in~\subref{sfig:harmless}, resulting in the code shown
in~\subref{sfig:nonssa},
where it inserted a store and a load instruction.
This is indicated by assigning to the memory location $X$.
The load is now a second definition of $x_0$, violating the SSA form that has
to be reconstructed as shown in~\subref{sfig:recons}.
This example shows that maintaining SSA also involves placing new \phifuns.

\begin{figure}[htbp]
  {\def\back{\kern1pt}
	\centering
	\subfloat[Original program] {
		\label{sfig:harmless}
                \tikzsubfigure[1]{spill}
		% \input spill_orig.tikz
	}
        \back
	\subfloat[Spilling~$x_0$, SSA broken] {
		\label{sfig:nonssa}
                \tikzsubfigure[2]{spill}
	}
        \back
	\subfloat[SSA reconstructed] {
		\label{sfig:recons}
                \tikzsubfigure[3]{spill}
	}
      }
	\caption{Adding a second definition as a side-effect of spilling.}
	\label{fig:ex1}
\end{figure}

Many optimizations perform such program modifications, and
maintaining SSA is often one of the more complicated and error-prone parts in
such optimizations, owing to the insertion of additional \phifuns and the
correct redirection of the uses of the variable.

\subsection{Jump Threading}

Jump threading is a transformation performed by many popular compilers such as GCC and LLVM.
It partially evaluates branch targets to save branches and provide more context to other optimizations.
Consider the situation where
a block contains a conditional branch that depends on some variable \var x.
In the example shown in Figure~\ref{fig:threading}, the conditional branch tests if $\var x> 0$.

Assume that the block containing that conditional branch has multiple predecessors and \var x can be proven constant for one of the predecessors.
In our example, this is shown by the assignment $\var x_1\gets~0$.
Jump threading now partially evaluates the conditional branch by directly making the corresponding successor of the branch block a successor of the \emph{predecessor} of the branch.
To this end, the code of the branch block is duplicated and attached to the predecessor.
This also duplicates potential definitions of variables in the branch block.
Hence, SSA is destroyed for those variables and has to be reconstructed.
However, in contrast to the previous spill example, the control flow has
changed which poses an additional challenge for an efficient SSA reconstruction
algorithm.

\begin{figure}[htbp]
  \begin{center}
    \subfloat[Original program]{
    \tikzsubfigure[1]{jump_threading}
    }
    \hfill
    \subfloat[Jump threaded]{
    \tikzsubfigure[2]{jump_threading}
    }
    \hfill
    \subfloat[SSA reconstructed]{
    \tikzsubfigure[3]{jump_threading}
    }
  \end{center}
  \caption{Jump Threading can break SSA, which has to be reconstructed.}
  \label{fig:threading}
\end{figure}


\section{General Considerations}
In this chapter, we will discuss two algorithms.
The first is an adoption of the classical dominance-frontier based algorithm.
The second performs a search from the uses of the variables to the definition and places \phifuns on demand at appropriate places.
In contrast to the first, the second algorithm might not construct minimal SSA
form in general;
However, it does not need to update its internal data structures when the CFG is modified.

We consider the following scenario: The program is represented as a control-flow graph (CFG) and is in SSA form with dominance property.
For the sake of simplicity, we assume that each instruction in the program only writes to a single variable.
%Due to the single assignment property of the SSA form, we can identify the program point of the instruction and the variable.
An optimization or transformation violates SSA by inserting additional definitions for an existing SSA variable, like in the examples above.
The original variable and the additional definitions can be seen as a single non-SSA variable that has multiple definitions and uses.

\todo{reprendre paragraphe}
In the following, $v$ will be such a non-SSA variable.
When reconstructing SSA for~$v$, we will first create fresh variables for every definition of~$v$ to establish the single-assignment property.
What remains is associating every use of~$v$ with a suitable definition.
In the algorithms, $v.\textrm{defs}$ denotes the set of all instructions that define $v$.
A use of a variable is a pair consisting of a program point (an instruction) and an integer denoting the index of the operand at this instruction.

Both algorithms presented in this chapter share the same driver routine
described in Algorithm~\ref{alg:ssaconstr_driver}.
First, we scan all definitions of $v$ so that
for every basic block $b$ we have the list $b.\textrm{defs}$ that contains all instructions in the block which define one of the variables in $v.\textrm{defs}$.
It is best to sort this according to the schedule of the instructions in the block from back to front, making, the latest definition the first in the list.

Then, all uses of the variable~$v$ are scanned.
Here we have to differentiate whether the use is in a \phifun or not.
If so, the use occurs at the end of the predecessor block that corresponds to the position of the variable in the $\phi$'s argument list.
In that case, we start looking for the reaching definition from the end of that block.
Otherwise, we scan the instructions of  the block backwards until we reach the first definition that is before the use (Line~\ref{l:before-use}).
If there is no such definition, we have to find one that reaches this block from \emph{outside.}

We use two functions, \ref{proc:find-def-from-begin} and \ref{proc:find-def-from-end} that search the reaching definition respectively from the beginning or the end of a block.
\ref{proc:find-def-from-end} actually just returns the last definition in the block, or call \ref{proc:find-def-from-begin} if there is none.

The two presented approaches to SSA repairing differ in the implementation of the function \ref{proc:find-def-from-begin}.
The differences are described in the next two sections.

\begin{algorithm}
	\caption{SSA Reconstruction Driver}
	\label{alg:ssaconstr_driver}
%proc ssa_reconstruct(variable v):
\KwIn{$v$, a variable that breaks SSA property}
\ForEach{$d \in v$.defs}{
    create fresh variable $v'$\;
    rewrite def of $v$ by $v'$ in $d$\;
    $b \gets d$.block\;
    insert $d$ in $b$.defs\;
%    according to schedule\Comment*{latest def. is first in list}
  }

  \ForEach{use $(\textrm{inst}, \mbox{index})$ of $v$}{
  \If{\textnormal{inst} is a \phifun}{
      $b \gets \textrm{inst}.\mbox{block}.\mbox{pred}(\textit{index})$\;
      $d \gets \textnormal{\ref{proc:find-def-from-end}}(v$, $b)$\;
    }
    \Else{
      $d \gets \bot$\;
      $b \gets \textrm{inst}.\mbox{block}$\;
      \ForEach{$l \in b.\mbox{defs}$ from bottom to top}{
      \If{$l$ is before $\textnormal{inst}$ in $b$}{\label{l:before-use}
          $d \gets l$\;
          break\;
        }
      }
%          \tcc*[f]{no local def. found, searching in the predecessors}
      \If(\Comment*[f]{no local def. found, searching in the 
        preds}){$d = \bot$}{
      $d \gets \textnormal{\ref{proc:find-def-from-begin}}(v$, $b)$\;
      }
    }
    $v' \gets $ version of $v$ defined by $d$\;
    rewrite use of $v$ by $v'$ in inst\;
  }
\end{algorithm}

\begin{procedure}
  \caption{FindDefFromBottom($v$, $b$)}
  \label{proc:find-def-from-end}
  \If{$b.\mbox{defs} \ne \emptyset$}{
  \Return{latest instruction in $b$.defs}\;
  }
  \Else{
    \Return{\textnormal{\ref{proc:find-def-from-begin}}($v$, $b$)}\;
  }
\end{procedure}

%proposed by Sastry and Ju~\cite{sastry98},
\section{Reconstruction based on the Dominance Frontier}
This algorithm follows the same principles as the classical SSA construction algorithm by Cytron at al.~as described in Chapter~\ref{chapter:classical_construction_algorithm}.
We first compute the iterated dominance frontier (\iDF) of~$v$.
This set is a sound approximation of the set where \phifuns must be placed---it might contain blocks where a \phifun would be dead.
Then, we search for each use~$u$ the corresponding reaching definition.
This search starts at the block of~$u$.
If that block $b$ is in the \iDF of~$v$, a \phifun needs to be placed at its entrance.
This \phifun becomes a new definition of $v$ and has to be inserted in $v.\textrm{defs}$ and in $b.\textrm{defs}$.
The operands of the newly created \phifun will query their reaching definitions by recursive calls to \ref{proc:find-def-from-end} on predecessors of $b$.
Because we inserted the \phifun into $b.\textrm{defs}$ \emph{before} searching for the arguments, no infinite recursion can occur (otherwise, it could happen for instance with a loop back edge).

If the block is not in the \iDF, the search continues in the immediate dominator of the block.
This is because in SSA, every use of a variable must be dominated by its definition.\footnote{The definition of an operand of a \phifun has to dominate the corresponding predecessor block.}
Therefore, the reaching definition is the same for all predecessors of the block, and hence for the immediate dominator of this block.

\begin{procedure}
  \caption{FindDefFromTop($v$, $b$)}
  \label{proc:def-from-end-ssaconstr}
  \Comment{SSA Reconstruction based on Dominance Frontiers}
  \If{$b \in \textnormal{\iDF($v$.defs)}$}{
    $v' \gets$ fresh variable\;
    $d \gets $ new \phifun in $b$: $v' \gets \phi(\dots)$ \;
    append $d$ to $b.\mbox{defs}$\;
%    $i \gets 0$\;
    \ForEach{$p \in b.\mbox{preds}$}{
      $o \gets \textnormal{\ref{proc:find-def-from-end}}(v$, $p)$\;
%      set $i$-th operand of $d$ to $o$\;
      $v' \gets $ version of $v$ defined by $o$\;
      set corresponding operand of $d$ to $v'$\;
%      $i \gets i + 1$\;
    }
  }
  \Else{
  $d \gets \textnormal{\ref{proc:find-def-from-end}}(v$, 
  $b.\mbox{idom})$\Comment*{search in immediate dominator}
  }
  \Return{d}
\end{procedure}

\section{Search-based Reconstruction}


The second algorithm presented here is adapted from an algorithm designed to construct SSA from the abstract syntax tree, but it also works well on control-flow graphs.
Its major advantage over the algorithm presented in the last section is that it does neither require dominance information nor dominance frontiers.
Thus it is well suited to be used in transformations that change the control-flow graph.
Its disadvantage is that potentially more blocks have to be visited during the reconstruction.
The principle idea is to start a search from every use to find the corresponding definition, inserting \phifuns on the fly while caching the SSA variable alive at the beginning of basic blocks.
As in the last section, we only consider the reconstruction for a single variable called~$v$ in the following.
If multiple variables have to be reconstructed, the algorithm can be applied to each variable separately.

\paragraph{Search on an acyclic CFG.}
The algorithm performs a backward depth-first search in the CFG to collect the reaching definitions of $v$ in question at each block,
recording the SSA variable that is alive at the beginning of a block in the ``beg'' field of this block.
If the CFG is an acyclic graph (DAG), all predecessors of a block can be visited before the block itself is processed, as we are using a post-order traversal following edges backward.
Hence, we know all the definitions that reach a block $b$: if there is more than one definition, we need to place a \phifun in $b$, otherwise it is not necessary.

\paragraph{Search on a general CFG.}
If the CFG has loops, there are blocks for which not all reaching definitions can be computed before we can decide whether a \phifun has to be placed or not.
In a loop, recursively computing the reaching definitions for a block $b$ will end up at $b$ itself.
To avoid infinite recursion, when we enter a block during the traversal, we first create a \phifun without arguments, ``\pendphi.''
This creates a new definition for $v$, $v\_\phi$, which is the variable alive at the beginning of this block.


When we return to $b$ after traversing the rest of the CFG, we decide whether a \phifun has to be placed in $b$ by looking at the reaching definition for every predecessor.
These reaching definitions can be either $v_\phi$ itself (loop in the CFG without a definition of $v$), or some other definitions of $v$.
If there is only one such other definition, say $w$, then this definition cannot be in a loop around $b$ or the program would not be strict.\todo{strictness not necessary}
In that case, it means \pendphi is not necessary and we can remove it, propagating $w$ downward instead of $v_\phi$. Otherwise, we keep \pendphi and fill its missing operands with the reaching definitions.

In this version of function \ref{alg:ssaconstr_click}, this check is done by the function \ref{proc:phi-necessary}.

\begin{procedure}
  \caption{FindDefFromTop($b$)}
  \label{proc:find-def-from-begin}
  \label{alg:ssaconstr_click}
  \Comment{Search-based SSA Reconstruction}
  \KwIn{$b$, a basic block}
\If{$b.\textnormal{top} \ne \bot$}{
    \Return{$b.\textnormal{top}$}
  }
  \pendphi $\gets$ new \phifun in $b$\;
  $v_\phi$ $\gets$ result of \pendphi\;
  $b.\mbox{top} \gets v_\phi$\;
  reaching\_defs $\gets []$\;
  \ForEach{$p \in b.\textrm{preds}$}{
  reaching\_defs $\gets$ reaching\_defs $\cup$ \textnormal{\ref{proc:find-def-from-end}}$(v$, $p)$
  }
  $v_\textrm{def}$ $\gets$ \ref{proc:phi-necessary}($v_\phi$, reaching\_defs)\;
  \If{$v_\textnormal{def}\, = v_\phi$}{
    set arguments of \pendphi to reaching\_defs\;
  }
  \Else{
    rewire all uses of \pendphi\ to $v_\textrm{def}$\;
    remove \pendphi\;
    $b.\mbox{top} \gets v_\textrm{def}$\;
  }
  \Return{$v_\textnormal{def}$}
\end{procedure}

\begin{procedure}
  \caption{Phi-Necessary($v_\phi$, reaching\_defs)}
  \label{proc:phi-necessary}
\Comment{Checks if the set reaching\_defs makes
\pendphi necessary. This is the case if it is a subset of
$\{v_\phi, \textrm{other}\}$}
\KwIn{$v_\phi$, the variable defined by \pendphi}
\KwIn{reaching\_defs, list of variables}
\KwOut{$v_\phi$ if \pendphi is necessary, the variable to use instead otherwise}
  $\textrm{other} \gets \bot$\;
  \ForEach{$v' \in \textrm{reaching\_defs}$}{
    \lIf{$v' = v_\phi$}{
      continue\;
    }
    \If{other = $\bot$}{
      other $\gets v'$
    }
    \ElseIf{$v' \ne \textrm{other}$}{
      \Return{$v_\phi$}
    }
  }
  \Comment{this assertion is violated if reaching\_defs contains only 
    pending\_$\phi$
  which never can happen}
  assert ($\textrm{other} \ne \bot$)\;
  \Return{other}
\end{procedure}

\paragraph{Removing more unnecessary \phifuns.}

In programs with loops, it can be the case that the local optimization performed when function \ref{alg:ssaconstr_click} calls \ref{proc:phi-necessary} does not remove all unnecessary \phifuns.
This can happen in loops where \phifuns can become unnecessary because other \phifuns are optimized away.
Consider the example in Figure~\ref{fig:phiopt}.
\begin{figure}[htbp]
	\begin{center}
		\subfloat[Original program] {
                  \tikzsubfigure[1]{phi-opt}
		}
		\qquad
		\subfloat[Unnecessary \phifuns] {
			\label{fig:unn_phi_left}
                  \tikzsubfigure[2]{phi-opt}
		}
	\end{center}
	\caption{Removal of unnecessary \phifuns.}
	\label{fig:phiopt}
\end{figure}
We look for a definition of $\var x$ from block~$E$.
If Algorithm~\ref{alg:ssaconstr_click} considers the blocks in a unfavorable order, e.g., $E,D,C,B,A,D,C$, some unnecessary \phifuns can not be removed by \ref{proc:phi-necessary}, as shown in Figure~\ref{fig:unn_phi_left}.
While the \phifun in block~$C$ can be eliminated by the local criterion applied by \ref{proc:phi-necessary}, the \phifun in block~$B$ remains.
This is because the depth-first search carried out by \ref{proc:find-def-from-begin} will not visit block~$B$ a second time.
To remove the remaining \phifuns, the local criterion can be iteratively applied to all placed \phifuns until a fixpoint is reached.
For reducible control flow, this then produces the minimal number of placed \phifuns.
The classical $(\ast)$-graph in Figure~\ref{fig:astgraph} illustrates that this does not hold for the irreducible case.

\begin{figure}
    \hfil\tikzfigure{ast-graph}\hfil\strut
    \caption{The irreducible $(\ast)$-Graph.}
    \label{fig:astgraph}
\end{figure}


\section{Conclusions}


The algorithms presented in this chapter are independent of the transformation that violated SSA and can be used as a black box:
For every variable for which SSA was violated, a routine is called that restores SSA.
Both algorithms rely on computed def-use chains because they traverse all uses from a SSA variable to find suitable definitions;
However, they differ in their prerequisites and their runtime behavior:
\begin{description}
	\item[First algorithm.]
		Choi et al.~\cite{Choi:1996ji} based this algorithm on the iterated dominance frontiers like the classical SSA construction algorithm by Cytron et al.~\cite{cytron:1991:ssa}.
		Hence, it is less suited for optimizations that also change the flow of control since that would require recomputing the iterated dominance frontiers.
		On the other hand, by using the iterated dominance frontiers, the algorithm can find the reaching definitions quickly by scanning the dominance tree upwards.
		Furthermore, one could also envision applying incremental algorithms to construct the dominance tree~\cite{Ramalingam:1994iq,Sreedhar:1995:ICD:202529.202531} and the dominance frontier~\cite{Sreedhar:1996:PLDI} to account for changes in the control flow.
		This has not yet been done and no practical experiences have been reported so far.

	\item[Second algorithm.]
		It does not depend on additional analysis information such as iterated dominance frontiers or the dominance tree.
		Thus, it is well suited for transformations that change the CFG because no information needs to be recomputed.
		On the other hand, it might be slower to find the reaching definitions because they are searched by a depth-first search in the CFG.
\end{description}

Both approaches construct \emph{pruned} SSA, i.e., they do not add dead \phifuns.
The first approach produces minimal SSA by the very same arguments Cytron et al.~\cite{cytron:1991:ssa} give.
The second is similar to the construction algorithm that Click describes in his thesis~\cite{click:thesis} to construct SSA from an abstract syntax tree, and only produce minimal SSA (in the sense of Cytron) in the case of reducible control flow.
This follows from the iterative application of the function \ref{proc:phi-necessary} which implements the two simplification rules presented by Aycock and Horspool~\cite{Aycock_Horspool_2000},
who showed that their iterative application yields minimal SSA on reducible graphs.
These two local rules can be extended to a non-local one which has to find strongly connected $\phi$-components that all refer to the same exterior variable.
Such a non-local check also eliminates unnecessary \phifuns in the irreducible case.\todo{citation?}

}
