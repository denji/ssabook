\chapter{Classical construction/update/destruction algorithm \Author{J. Singer, F. Rastello}}
\inputprogress

{
\def\phiops{$\phi$-functions}
\def\phiop{$\phi$-function}

%% jsinger - simple introductory paragraphs

This chapter describes the standard algorithms for SSA \textit{construction} and
\textit{destruction}.

SSA construction refers to the process of translating a non-SSA program into
one that satisfies the SSA constraints. In general, this transformation
occurs as one of the
earliest phases in the middle-end of an optimizing compiler, when the program
has been converted to three-address intermediate code.
SSA destruction is sometimes called out-of-SSA translation. This phase
takes place in an optimizing compiler after all SSA optimizations have
been performed, and prior to code generation. (However note that there are
specialized code generation techniques that work directly on SSA-based
intermediate representations. \emph{FIXME - forward ref})

The algorithms presented in this chapter are simple and pragmatic, hence they
are the most widely implemented in current compilers. Note that more
efficient, albeit more complex, alternative algorithms have been devised.
These are reviewed in \emph{FIXME - forward refs to subsequent chapters}.

\section{Simple programming language model}

Throughout this chapter,
we assume that a `program' is represented as an
intraprocedural control flow graph,
with a single entry node $r$, from which every other
node is reachable.
\emph{FIXME - precise definition of CFG in appendix?}
Data flow occurs through definitions and uses of 
local variables, with no pointer indirection.
\emph{FIXME - forward references to chapters dealing with
SSA extensions for complex features like memory, concurrency, etc}
% No constraints on control-flow structures in CFG
% (unlike in syntax-directed SSA construction algorithms).



\section{Construction}
{\em We need the notion of CFG, $r$ the entry node. Need the notion of
  dominance, and (iterated)-dominance-frontier. Need the notion of reaching
  definition. Give pointers to relevant appendix definitions.}


% Transforming a code that has no \phiops\ to a code that has SSA form is
% called SSA construction.
The original construction algorithm for SSA form \cite{cytron91efficiently}
divides into two distinct phases.
\begin{enumerate}
\item \textbf{\phiop\ insertion} ensures that any use of a given variable $v$ is reached 
%(without traversing another definition of $v$)
%%%% jsinger - reaching definitions explanation will
%%%% outline how traversing a new def kills the previous
%%%% reaching def.
by exactly one definition of $v$. In other words, this first phase of \phiop\ insertion performs \textit{live-range splitting}.
The resulting live-ranges have the property of having a single definition, which occurs at the beginning of each live range.
\item \textbf{variable renaming} assigns a unique variable name to each live-range. This second phase rewrites variable names in program statements such that the program text contains only one definition of each variable, and every use refers to its corresponding unique reaching definition.
\end{enumerate}

As already outlined in Chapter \emph{FIXME - 2}, there are different flavors of SSA with distinct properties. In this chapter, we focus on the \textit{minimal} SSA form. Construction of minimal SSA 
(which is not completely minimal as we will see further) 
requires the insertion of \phiops\ at \textit{join nodes},
i.e.\ nodes in the CFG that can be reached by two or more distinct definitions of the same variable using disjoint paths. 
%% jsinger - is the disjoint paths qualification necessary, if we define "reaching definitions" carefully?
%%
% FAB: in fact Cytron et al. iterate on join sets. Weiss said that J+(S)=J(S). So removed the citation that was useless
Given the assumption that each variable has a {\em pseudo-definition} at the root~$r$ of the CFG, the set of join nodes for a variable definition corresponds exactly to the iterated dominance frontier of that definition.
\emph{FIXME - this previous sentence needs to be tidied up.}

We end up with a straightforward algorithm that places \phiops\ on a per-variable basis.
For a given variable $v$, we place \phiops\ at the iterated dominance frontier $DF^{+}(S)$ of the set of definition points $S$ for $v$. 
If we assume, not unreasonably, that the dominance frontier of each CFG node is precomputed, then the \phiops\ can be inserted iteratively using a worklist of definition points, and flags (to avoid multiple insertions). 
This gives the following pseudo-code for the \phiop\ insertion algorithm:
\begin{verbatim}
proc phi_insertion
// places phi functions at the iterated dominance frontier
  foreach global variable v
    let Worklist:=definitions(v)
        typeof(Worklist) == CFGNode List
    let Inserted:=emptyset
        typeof(Inserted) == CFGNode List
    foreach D in Worklist
        typeof(D) == statement
      foreach I in DF(D) \ Inserted
        typeof I == CFGNode
        insert "v=phi(v,...,v)" @ beginning of node I
        Inserted += {I}
\end{verbatim}
\emph{jsinger - Hi Fabrice, I think it would be helpful to include
types for variables in this algorithm. At the moment, there is some confusion
over CFG nodes and individual statements. We need to resolve this...}

Once \phiops\ have been inserted using this algorithm, the program may still contain several definitions per variable, however there is a static single definition statement that reaches each use. Moreover, with the following semantics for \phiops\ where its variable uses are considered to be on the corresponding predecessor basic blocks, then use-def chains are aligned with the CFG dominance tree. In other word the unique definition that reaches each use dominates that use.

To obtain a code with a static single assignment per variable, it is necessary to perform variable renaming. Because of the dominance property outlined above,
renaming can be easily achieved using a DFS traversal of the dominance tree.
During the traversal, for each variable $v$, it is necessary to remember its nearest dominating definition.
This gives the following pseudo-code for the variable renaming algorithm:
\begin{verbatim}
proc renaming:
// rename variable def and use to have one definition per variable
  foreach v: Variable
    let v.reachingDef:=undef
  foreach B: basicBlock in DFS preorder of the dominance tree
    foreach inst: instruction from top to bottom of B
      foreach o: a use operand of inst
        let v the variable used in o
        v.update_reachingDef(o)
        replace v by v.reachingDef in o
      foreach o: a def operand of inst
        let v the variable used in o
        v.update_reachingDef(o)
        create new variable v'
        replace v by v' in o
        v'.reachingDef:=v.reachingDef
    foreach phi: phi instruction in a successor of B
      foreach o: a use operand of phi
        let v the variable used in o
        v.update_reachingDef(o)
        replace v by v.reachingDef in o
\end{verbatim}

\begin{verbatim}
proc v.update_reachingDef(o):
// simply go up along the reachingDef chain until dominance is fulfilled 
  let rd:=v.reachingDef
  while not (rd==undef || def(rd) dominates o)
    rd:=rd.reachingDef
  v.reachingDef:=rd
\end{verbatim}

As detailed and explained further \emph{(in Philip's chapter?)}, this simple algorithm constructs programs in a SSA form that is \textit{minimal} (with the meaning given by Cytron et al.).
The SSA code could be \textit{pruned} (some dead \phiops\ are unnecessarily inserted).
It is \textit{conventional} SSA (the transformation that renames back all $\phi$-related variables into a unique representative one, and removes all \phiops\ is a correct SSA-destruction algorithm).
Finally, such SSA has the \textit{dominance} property (each variable use is dominated by its unique definition).

\section{Turning general SSA into conventional/pruned/dominance property}

Discussion regarding relationship between minimal and pruned SSA, etc.
$phi$-function removal can give pruned SSA but break
dominance properties, etc. Keep this section simple, and don't duplicate
material from Philip Brisk in previous chapter.
Ask Philip who may have some materials for the ``turning into SSA with dominance property'' part.


\section{Destruction \Author{F. Rastello}}
\label{sec:classical_destruction}

SSA form is a simple and efficient way of having sparse representation of some program information used by some code analysis and optimization. Once we are done with SSA based optimizations, or at least before code generation, one have to get rid of \phiops\ that are not machine instructions. This phase is called SSA destruction. 
Destructing a freshly constructed SSA code is easy. One just have to first rename back into a unique representative variable all $\phi$-related variables (called SSA-webs) that had initially the same name. Then each \phiop\ have all its operands identical and can be removed to coalesce the related live-ranges.
Finding SSA-webs can be performed efficiently using the classical union-find algorithm for merging sets:
\begin{verbatim}
proc find_webs
// find the ssa web of each variable
foreach variable v:
  ssaweb(v) := {v}
foreach instruction of the form "a=phi(a1,...,an)"
  foreach ai union(ssaweb(a),ssaweb(ai))
\end{verbatim}

An SSA form is said to be conventional if for each ssaweb, all its variables can be safely renamed into a unique representative one. In other words each SSA web should be interference free. While a freshly constructed SSA code is conventional, this may not be the case after optimizations such as copy folding have been performed.

The simplest (but not the more efficient) way for destructing non conventional SSA form is to split all (critical) edge, and then replace \phiops\ by parallel copies on predecessor blocks. By splitting an edge say ($s,d)$, we mean replacing it by an edge from $s$ to a freshly created basic block and by another edge from this new basic block to $d$.

{\em Provide a simple but not optimal pseudo code for parallel copy sequentialization. Provide the pseudo-code for $\phi$-function replacement.}

We should outline that this technique has several drawbacks: first because of specific architectural constraints, region boundaries, or exception handling code, the compiler might not allow to split a given edge; second, the obtained code contains many additional temporary-to-temporary copies. In theory, coping with these copies is the role of the coalescer during the register allocation phase. But only decoupled register allocators (such as the one detailed in Chapter~\ref{ chap:register-allocation}) with memory and time consuming coalescing heuristics can handle the removal of these copies efficiently. Coalescing can also, with less efforts, be handled prior to the register allocation phase. As opposed to a (so called conservative) coalescer during register allocation, this so called aggressive coalescing would not cope with the interference graph colorability. Still the insertion of copies itself might take a substantial amount of time and might not be suitable for dynamic compilation. The goal of Chapter~\ref{chap:alternative-destruction} is to cope both with non splittable edges and difficulties related with SSA destruction at machine code level, but also aggressive coalescing in the context of resource constrained compilation.

}
