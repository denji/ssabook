\chapter{Introduction
  \Author{M. Schordan \andAuthor F. Rastello}}
\label{chapter:analysis}
\inputpath{part3}{analysis}
\inputprogress

The goal of this chapter is to provide an overview of the benefits of
SSA for program analyses and optimizations. We illustrate how SSA
makes an analyses more convenient because of its similarity to
functional programs. Technically, the def-use chains explicitly
expressed through the SSA graph, but also the static-single
information property, is what makes SSA so convenient.

\ifconstantprop

There are several analysis that propagate information through the SSA
graph.  The \emph{chapter ``propagation
  engine''}\ref{chapter:constant_propagation_is_easier} gives a
somehow general description of the mechanism.

TODO: refine following key points

\begin{itemize}
\item shows how SSA form facilitates the design and implementation of analyses equivalent to traditional data flow analyses.
\item SSA property allows to reduce analysis time and memory consumption
\item Presented {\em Propagation Engine} is an extension of the well-known approach by Wegman and Zadeck for sparse conditional constant propagation.
\item Basic algorithm not limited to constant propagation
\item allows to solve a large class of data-flow problems more efficiently than the iterative work list algorithm for solving data flow equations. The basic idea is to directly propagate information computed at the unique defition of a variable to all its uses
\item Data flow analyses based on SSA form rely on specialized program representation based on SSA graphs which resemble traditional use-def chains.
\item BUT: not all data flow analyses can be modeled.
\end{itemize}

\fi

As already mentioned in Chapter~\ref{chapter:properties_and_flavors},
SSA form can come in different flavors. The vanilla one is strict SSA, or said
equivalently, SSA form with the dominance property. The most common SSA
construction algorithm exploits this dominance property by two means:
First it allows to compute join sets for $\phi$-placement in a very
efficient way using the dominance frontier.  Second it allows variable
renaming using a folding scheme along the dominance tree.  The notion
of dominance and dominance frontier are two structural properties that
make SSA form singular for compiler analysis and transformations.

Those two aspects are illustrated in this part through two chapters:
Chapter~\ref{chapter:ssa_tells_nothing_of_liveness} shows how loop
nesting forest and dominance property can be exploited to devise very
efficient liveness analysis; Chapter~\ref{chapter:pre_not_helped}
shows how the dominance frontier that allows to insert a minimal number of
\phifun\ for SSA construction can also be used to minimize redundant
computations.

\paragraph{Faster Liveness Analysis with SSA form}
A data-flow analysis iterates potentially up to as many times as the
maximum loop depth of a given program until it stabilizes and
terminates. In contrast, the properties of SSA form allow to
accelerate liveness analysis without the requirement of any iteration
to reach a fixed point: it only requires at most two passes over the
CFG. Also an extremely simple liveness check is possible by providing
a query system to answer questions such as ``is variable $v$ live at
location $q$?''.

We first present an algorithm for computing liveness information on
reducible CFGs and continue with deriving an algorithm that can also
be applied to irreducible graphs. This can be achieved by transforming
an irreducible graph into a reducible graph such that the liveness in
both graphs is equivalent. In practice we do not modify the graph, but
adapt the algorithm for reducible graphs such that it simulates the
modification of some edges on the fly.

%SSA simplifies, accelerates liveness analysis.
%Ususal approach: data-flow abnalysis iteratively (potentially as many times as max loop depth).
%Live-in of a loop, then live everywhere in the loop.
%Dominance => live everywhere in a loop then live-in of a loop.
%live-in of a loop in the CFG then also live-in of loop in forward CFG (and reciproquely) => compute all loop headers where variable is alive using data-flow (without any iterations).
%Chapter presents also two other approaches: 1. path exploration (variable live if belongs path from definition to use -- SSA does not help much for this algorithm but for sumarising better liveness within a BB); 2. 

%live-range has following property: v live at program point q if and only if v is live at the entry of the largest loop/basic-block that contains q but not the definition of v; v is live at h if and only if there is a path in the forward-CFG from h to a use of v that does not contain the definition.

%In this section we illustrate how the structural properties of SSA are useful. 
%The first one is the dominance property whic underlying tree structure is really interesting. 
%We can do any greedy or dynamic programming along this tree. 
%We illustrate the advantages of dominance property on \emph{liveness analysis} and check. 

\paragraph{Loop Tree and Induction Variables}

%\emph{``chapter on scalar evolution''}
Chapter \ref{chapter:loop_tree} illustrates how capturing properties of the SSA graph
itself (circuits) can be used to determine induction variables.

TODO: refine following key points

\begin{itemize}
\item extraction of the reducible loop tree can be done on the SSA graph itself
\item the induction variable analysis is based on the detection of self references in the SSA representation and on its characterization
\item algorithm translates the SSA representation into a representation of polynomial functions, describing the sequence of values that SSA variables hold during the execution of loops.
\item Number of iterations is computed as the minimum solution of a polynomial inequality with integer solutions, also called Diophantine inequality.
\end{itemize}

\paragraph{Relation between Partial Redundancy Elimination and SSA form}

The elimination of redundant computations is an important compiler
optimization. In chapter \ref{chapter:pre_not_helped} we show that the
dominance frontiers that define where \phifuns\ are inserted
in SSA form also form the ``frontier'' between full redundancy and
partial redundancy. A computation is {\em fully redundant} if it has
also occurred earlier regardless of control flow, a computation is {\em
  partially redundant} if it is has occurred earlier only on certain
paths. Following the program flow, once we are past the dominance
frontiers, any further occurrence of a redundant expression is
partially redundant, whereas any occurrence before the dominance
frontier is fully redundant. The difference for the optimization is
that fully redundant expressions can be deleted, whereas for
(strictly) partially redundant expressions insertions are required to
eliminate the redundancy. Thus, since partial redundancies start at
dominance frontiers they are related to SSA's $\phi$ statements. In
chapter \ref{chapter:pre_not_helped} on SSAPRE we present an
algorithm, named SSAPRE, performing partial redundancy elimination
(PRE) by efficiently taking advantage of the use-def information
inherent in its input conventional SSA form. SSAPRE builds redundancy
edges between redundant expressions (in SSA form) and has the effect
of factoring the redundancy edges at merge pointer in the CFG. The
resulting {\em factored redundancy graph (FRG)} can be regarded as the
SSA form for expressions. We also discuss speculative code motion
which suppresses redundancy in some path at the expense of another
path where the computation is added but the result is unused.

%Global value numbering like algorithms such as the
%one descibed at the end of chapter ``PRE''\ref{chapter:pre_not_helped}
%but also the more general PRE of \emph{Van Drunen} is also a perfect
%illustrattion.  We roughly describe this last algorithm here.

This PRE algorithm is not capable of recognizing redundant
computations among lexically different expressions that yield the same
value. Therefore we also discuss redundancy elimination based on value
analysis, which can determine redundancy whenever two computations
yield the same value. A technique for such a value analysis is {\em
  value numbering}. In this case the benefit of SSA form is that it
enables value numbering to be easily extended to the global scope,
called {\em global value numbering}, because each SSA version of a
variable corresponds to at most one static value for the variable.

%\section{Sparse Analysis}
%In this section we illustrate through an important problem (\emph{alias analysis}) how SSA really helps in having effective analysis on complex problems. 
%This is about sparsity (as mentioned in chapter ``Properties of SSA'') which is provided by the SSA form as an ``optimal'' (minimal size) sparse evaluation graph. 
%For that we report the work of Ben and Li on sparse analysis. 
%We take the opportunity to outline that we can start from (partial) SSA as top level variables already provide insightful information for this analysis. 
%I we believe other variables (that alias with others) must be used for this analysis, and want fully sparse analysis then we need to consider SSA extensions such as HSSA.

