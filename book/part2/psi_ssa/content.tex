\chapter{Psi-SSA Form \Author{F. de Ferri\`ere}}
\inputprogress
\label{chapter:psi_ssa}

\section{Overview}

% Explain why SSA renaming cannot be applied on predicated definitions. 

% The $\psi$-SSA representation was developed to extend the SSA
% representation with support for predicated operations.

In the SSA representation, each definition of a variable is given a
unique name, and new pseudo definitions are introduced on \phifuns to merge values coming from different control-flow paths. An
example is given figure~\ref{fig:op_ssa}(b). Each definition is an
unconditional definition, and the value of a variable is the value of
the expression on the unique assignment to this variable. This
essential property of the SSA representation does not any longer hold
when definitions may be conditionally executed. When a variable is defined by a predicated operation, the value of the variable
will or will not be modified depending on the value of a guard
register. As a result, the value of the variable after the predicated
operation is either the value of the expression on the assignment if
the predicate is true, or the value the variable had before this
operation if the predicate is false. This is represented in
figure~\ref{fig:op_ssa}(c) where we use the notation $p\cond a = \texttt{op}$ to indicate that an operation $a = \texttt{op}$ is executed only if predicate $p$ is true, and is ignored otherwise. We will also use the notation $\overline{{p}}$ to refer to the complement of predicate \textit{p}.
The goal of the $\psi$-SSA form advocated in this chapter is to express these conditional definitions while keeping the static single assignment property.

\begin{figure}
\footnotesize
\subfloat[non-SSA]{
\begin{tabular}{l}
${a = \texttt{op1}};$ \\
\iftt ${(p)}$\\
\thentt\\
$\ \ \ \ a = \texttt{op2};$\\
\\
${\ \ = a}$ \\
\\
\end{tabular}
} \hfill
\subfloat[SSA]{
\begin{tabular}{l}
 ${a}_1 = \texttt{op1};$ \\
 \iftt ${(p)}$      \\
 \thentt\\
$\ \ \ \ a_2 = \texttt{op2};$ \\
${a}_3 = \phi({a}_1, {a}_2)$ \\
${\ \ = a}_3$            \\
\\
\end{tabular}
}\hfill
\subfloat[With predication]{
\begin{tabular}{lp{2cm}}
            & ${a}_1 = \texttt{op1};$\\
&\\
&\\
 ${p?}$ & ${a}_2 = \texttt{op2};$ \\
&\\
            & ${\ = a_{??}}$ \\
\\
\end{tabular}
}\hfill
\subfloat[$\psi$-SSA]{
\begin{tabular}{ll}
            & ${a}_1 = \texttt{op1};$\\
&\\
&\\
 ${p?}$ & ${a}_2 = \texttt{op2};$ \\
& $a_3=\psi(a_1,p?a_2)$\\
            & ${\ = a_3}$ \\
\\
\end{tabular}
}
\caption{SSA representation}
\label{fig:op_ssa}
\end{figure}

\section{Definition and Construction}


% Gives the semantics of the PSI function, doing the parallel with PHI
% function before if-conversion. Explain the relation between the
% predicates on the definition and the predicates in the PSI. Explain
% how a PSI function is executed.

Predicated operations are used to convert control-flow regions into
straight-line code. Predicated operations may be used by the intermediate
representation in an early stage of the compilation process as a result of inlining intrinsic functions. Later on, the compiler may
also generate predicated operations through if-conversion optimizations
as described in chapter~\ref{chapter:if_conversion}.


In figure~\ref{fig:op_ssa}(c), the use of \textit{a} on the last
instruction refers to the variable ${a_1}$ if \textit{p} is false, or
to the variable ${a_2}$ if \textit{p} is true. These multiple
reaching definitions on the use of \textit{a} cannot be represented by
the standard SSA representation.
%
One possible representation would be to use the Gated SSA form,
presented in chapter~\ref{chapter:vsdg}. In such a representation, the
\phifun would be augmented with the predicate \textit{p} to tell
which value between ${a_1}$ and ${a_2}$ is to be
considered. However, Gated-SSA is a completely different intermediate
representation where the control-flow is no longer represented. This
representation is more suited for program interpretation than for optimizations at code generation level as addressed in this chapter.
%
Another possible representation would be to add a reference to ${a_1}$
 on the definition of ${a_2}$. $p\cond a_2=\texttt{op2} {\color{gray}~|~a_1}$ 
would have the following semantic: ${a_2}$ takes the value computed by $\texttt{op2}$ if $p$ is true, or holds
the value of ${a_1}$ if \textit{p} is {false}. The use of \textit{a} on the last instruction of Figure~\ref{fig:op_ssa}(c)
would now refer to the variable ${a_2}$, which holds the correct
value. The drawback of this representation is that it adds
dependencies between operations (here a flow dependence from \texttt{op1} to \texttt{op2}), which would prevent code reordering
for scheduling. 

Our solution is presented in figure~\ref{fig:op_ssa}(d). The $\phi$-function of the SSA code with control-flow
 is ``replaced'' by a $\psi$-function on the corresponding predicated code, with information on the
predicate associated with each argument. This representation is
adapted to code optimization and code generation on a low-level
intermediate representation.
%
A \psifun ${a_0 = \psi({p}_1?{a}_1,\ \dots,\ {p}_i?{a}_i,\
  \dots,\ {p}_n?{a}_n)}$ defines one variable, ${a_0}$,
and takes a variable number of arguments ${a_i}$; each
argument ${a_i}$ is associated with a predicate ${p_i}$. In
the notation, the predicate ${p_i}$ will be omitted if
${p_i} \equiv \textrm{true}$.
\newpage
A \psifun has the following properties:
\begin{itemize}

\item{\emph{It is an operation}}~: A \psifun is a regular operation. It
  can occur at any location in a basic block where a regular operation
  is valid. Each argument ${a_i}$, and each predicate ${p_i}$,
  must be dominated by its definition.

\item{\emph{It is predicated}}~: A \psifun is a predicated
  operation, under the predicate ${\bigcup_{k=1}^n p_k}$,
  although this predicate is not explicit in the representation.

\item{\emph{It has an ordered list of arguments}}~: The order of the
  arguments in a \psifun is significant. A \psifun is
  evaluated from left to right. The value of a \psifun is the
  value of the right most argument whose predicate evaluates to true.

\item{\emph{Rule on predicates}}~: The predicate ${p_i}$ associated
  with the argument ${a_i}$ in a \psifun must be included
  in or equal to the predicate on the definition of the variable ${a_i}$.
In other words, for the code $q\cond {a}_i = \texttt{op}$;  ${a}_0 = {\psi}(\dots,\ {p}_i?{a}_i,\dots)$, we must have 
${p}_i \subseteq {q}$ (or $p_i \Rightarrow q$).

\end{itemize}

\begin{figure}[h]
\begin{center}
\footnotesize
\hfill
\subfloat[Control-flow code]{
\begin{tabular}{p{3cm}}
\iftt ${(p)}$\\
\thentt   \\
${\ \ \ \ \ a_1 = 1;}$\\
\elsett \\
${\ \ \ \ \     a_2 = -1;}$\\
${x_1 = \phi(a_1, a_2)}$\\
\iftt ${(q)}$\\
\thentt\\
${\ \ \ \ \ a_3 = 0;}$\\
${x_2 = \phi(x_1, a_3)}$\\
\end{tabular}
} \hfill
\subfloat[Predicated code]{
\begin{tabular}{lp{3cm}}
&\\
& \\
 ${p?}$ & ${a_1 = 1;}$ \\
\\
 ${\overline{p}?}$ & ${a_2 = -1;}$ \\
& ${x_1 = \psi(p?a_1, \overline{p}?a_2)}$ \\
\\
\\
 ${q?}$ & ${a_3 = 0;}$ \\
& ${x_2 = \psi(p?a_1, \overline{p}?a_2, q?a_3)}$ \\
\end{tabular}
}
\hfill
\caption{$\psi$-SSA with non-disjoint predicates}
\label{fig:non_disjoint_pred}
\end{center}
\end{figure}

A \psifun can represent cases where variables are defined on arbitrary independent
predicates such as $p$ and $q$ in the example of Figure~\ref{fig:non_disjoint_pred}~: For this example, during the SSA
construction a unique variable \textit{a} was renamed into the variables
${a_1}$, ${a_2}$ and ${a_3}$ and the variables ${x_1}$
and ${x_2}$ were introduced to merge values coming from different
control-flow paths. In the control-flow version of the code, there is a
control-dependency between the basic-block that defines ${x_1}$ and the operation that defines ${a_3}$, which means
the definition of ${a_3}$ must be executed after the value for
${x_1}$ has been computed. In the predicated form of this example,
there is no longer any control dependencies between the definitions of
${a_1}$, ${a_2}$ and ${a_3}$. A compiler transformation
can now freely move these definitions independently of each other,
which may allow more optimizations to be performed on this
code. However, the semantics of the original code requires that the
definition of ${a_3}$ occurs after the definitions of ${a_1}$
and ${a_2}$. The order of the arguments in a \psifun gives
information on the original order of the definitions. We take the
convention that the order of the arguments in a \psifun is,
from left to right, equal to the original order of their definitions,
from top to bottom, in the control-flow dominance tree of the program
in a non-SSA representation. This information is needed to maintain
the correct semantics of the code during transformations of the
$\psi$-SSA representation and to revert the code back to a non
$\psi$-SSA representation.


The construction of the $\psi$-SSA representation is a small
modification on the standard algorithm to built an SSA representation (see Section~\ref{sec:classical_construction}).
%
The insertion of \psifuns is performed during the SSA renaming
phase.
%
During the SSA renaming phase, basic blocks are processed in their
dominance order, and operations in each basic block are scanned from
top to bottom. On an operation, for each predicated definition of a
variable, a new \psifun will be inserted just after the
operation~: Consider the definition of a variable \textit{x} under predicate
${p_2}$ ($p_2\cond x= \texttt{op}$); suppose ${x_1}$ is the current version of $x$ before
to proceeding \texttt{op}, and that $x_1$ is defined through predicate $p_1$ (possibly true); after renaming $x$ into a freshly created version, say $x_2$, a \psifun of the form ${x = \psi(p_1?x_1,
  p_2?x)}$, is inserted right after \texttt{op}. 
Then renaming of this new operation proceeds. The first argument of
the \psifun is already renamed and thus is not modified. The
second argument is renamed into the current version of \textit{x}
which is ${x_2}$. On the definition of the \psifun, the
variable \textit{x} is given a new name, ${x_3}$, which becomes the
current version for further references to the \textit{x} variable. This
insertion and renaming of a \psifun is shown on
Figure~\ref{fig:psi_ssa_construct}.

\begin{figure}[h]
\footnotesize
\subfloat[Initial]{
\begin{tabular}{ll}
${p_2?}$ & ${x = \texttt{op}}$\\
\\
\end{tabular}
}\hfill
\subfloat[$\psi$-insertion]{
\begin{tabular}{ll}
 ${p_2?}$ & ${x = \texttt{op}}$ \\
           & ${x = \psi(p_1?x_1, p_2?x)}$ \\
\end{tabular}
} \hfill
\subfloat[\texttt{op}-renaming]{
\begin{tabular}{ll}
 ${p_2?}$ & ${x_2 = \texttt{op}}$ \\
           & ${x = \psi(p_1?x_1, p_2?x_2)}$ \\
\end{tabular}
} \hfill
\subfloat[$\psi$-renaming]{
\begin{tabular}{ll}
 ${p_2?}$ & ${x_2 = \texttt{op}}$\\
           & ${x_3 = \psi(p_1?x_1, p_2?x_2)}$ \\
\end{tabular}
}
\caption{Construction and renaming of $\psi$-SSA}
\label{fig:psi_ssa_construct}
\end{figure}


\psifuns can also be introduced in an SSA representation by
applying an if-conversion transformation, such as the one that is
described in Chapter~\ref{chapter:if_conversion}. Local transformations
on control-flow patterns can also require to replace \phifuns
by \psifuns.

\section{SSA algorithms}


% Explain how standard SSA algorithm can be adapted to the Psi-SSA
% form: Predicated definitions are now seen as non-predicated ones,
% and a semantics, similar to the similar of PHI functions, must be
% defined for PSI functions.

With this definition of the $\psi$-SSA representation, implicit data-flow links to predicated operations are now explicitly expressed through \psifuns. Usual algorithms that perform
optimizations or transformations on the SSA representation can now be
easily adapted to the $\psi$-SSA representation, without compromising
the efficiency of the transformations performed. Actually, within the
$\psi$-SSA representation, predicated definitions behave exactly the
same as non predicated ones for optimizations on the SSA
representation. Only the \psifuns have to be treated in a
specific way. As an example, the classical constant propagation
algorithm under SSA can be easily adapted to the $\psi$-SSA
representation. In this algorithm, the only modification is that
\psifuns have to be handled with the same rules as the \phifuns. Other algorithms such as dead code elimination, global
value numbering, partial redundancy elimination, and induction
variable analysis are examples of algorithm that can easily be adapted
to this representation with minor efforts.

\section{Psi-SSA algorithms}


% Special transformations can be applied on Psi-SSA, which allows to
% optimize predicated code. Explain on an example what are the uses of
% inlining, reduction, projection and predicate promotion.

In addition to standard algorithms that can be applied to \psifuns and predicated code, a number of specific transformations
can be performed on the \psifuns, namely $\psi$-inlining,
$\psi$-reduction, $\psi$-projection, $\psi$-permutation and
$\psi$-promotion. For a \psifun ${a_0 = \psi(p_1?a_1, ...,
  p_i?a_i, ..., p_n?a_n)}$, those transformations are defined as
follows:

~\\
{\bf $\psi$-inlining} recursively replaces in a $\psi$
  function an argument ${a_i}$ that is defined on another $\psi$
  function by the arguments of this other \psifun. The
  predicate ${p_i}$ associated with argument ${a_i}$ will be distributed
  with an \texttt{and} operation over the predicates associated with the
  inlined arguments. This is shown in figure~\ref{fig:psi_inlining}.
\begin{figure}[h]
\begin{center}
\footnotesize\hfill
{
\begin{tabular}{ll}
             & ${a_1 = \texttt{op}1}$  \\
${p_2?}$ & ${a_2 = \texttt{op}2}$        \\
             & ${x_1 = \psi(a_1,\ p_2?a_2)}$\\
${p_3?}$ & ${a_3 = \texttt{op}3}$             \\
             & ${x_2 = \psi(p_1?x_1,\ p_3?a_3)}$ \\
\end{tabular}
} \hfill
{
\begin{tabular}{ll}
                & ${a_1 = \texttt{op}1}$ \\
 ${p_2?}$ & ${a_2 = \texttt{op}2}$ \\
           & \color{gray} $x_1 = \psi(a_1,\ p_2?a_2)$ // dead \\
 ${p_3?}$ & ${a_3 = \texttt{op}3}$ \\
         & ${x_2 = \psi(p_1?a_1,\ p_1\wedge p_2?a_2,\ p_3?a_3)}$ \\
\end{tabular}
}
\caption{$\psi$-inlining of the definition of $x_1$}
\label{fig:psi_inlining}
\end{center}
\end{figure}

~\\
{\bf $\psi$-reduction} removes from a \psifun an
  argument ${a_i}$ whose value will always be overridden by arguments on
  its right in the argument list. An argument ${a_i}$ associated
  with predicate ${p_i}$ can be removed if ${p_i \subseteq
    \bigcup_{k=i+1}^n p_k}$. This can be illustrated by the example of
  Figure~\ref{fig:psi_reduction}.



\begin{figure}[h]
\begin{center}
\footnotesize
\hfill
\begin{tabular}{ll}
             & ${a_1 = \texttt{op}1}$  \\
${p_2?}$ & ${a_2 = \texttt{op}2}$        \\
${\overline{p_2}?}$ & ${a_3 = \texttt{op}3}$ \\
             & ${x_2 = \psi(a_1, p_2?a_2, \overline{p_2}?a_3)}$\\
\end{tabular}\hfill
\begin{tabular}{ll}
      & ${a_1 = \texttt{op}1}$ \\
 ${p_2?}$ & ${a_2 = \texttt{op}2}$ \\
 ${\overline{p_2}?}$ & ${a_3 = \texttt{op}3}$ \\
        &${x_2 = \psi(p_2?a_2, \overline{p_2}?a_3)}$ \\
\end{tabular}
\caption{$\psi$-reduction. The first argument  $a_1$ of the \psifun can safely be removed}
\label{fig:psi_reduction}
\end{center}
\end{figure}

\textbf{$\psi$-projection} creates from a \psifun a
  new \psifun on a restricted predicate say $p$.  In this new \psifun, an argument ${a_i}$ initially guarded by $p_i$ shall be guarded by the conjunction $p_i\wedge p$. If $p_i$ is known to be disjoint with $p$, $a_i$ actually
  contributes no value to the \psifun and thus can be
  removed. $\psi$-projection on predicate $p$ is usually performed when the result of a \psifun is used in an operation predicated by $p$. This is illustrated in Figure~\ref{fig:psi_projection}.

\begin{figure}[h]
\footnotesize
\hfill
\begin{tabular}{llp{3cm}ll}
${p_2?}$ & ${a_2 = \texttt{op}2}$             & \ \ \ \ \ \ \ \  & ${p_2?}$ & ${a_2 = \texttt{op}2}$ \\
${\overline{p_2}?}$ & ${a_3 = \texttt{op}3}$              & \ \ \ \  & ${\overline{p_2}?}$ & ${a_3 = \texttt{op}3}$ \\
             & ${x_2 = \psi(p_2?a_2, \overline{p_2}?a_3)}$ & \ \ \ \  &              &${x_2 = \psi(p_2?a_2, \overline{p_2}?a_3)}$ \\
             &                               & \ \ \ \  &              & ${x_3 = \psi(p_2?a_2)}$ \\
${p_2?}$ & ${y_1 = x_2}$              & \ \ \ \  & ${p_2?}$ & ${y_1 = x_3}$ \\
\end{tabular}
\caption{$\psi$-projection of $x_2$ on $p_2$. Second argument $a_3$ can be removed.}
\label{fig:psi_projection}
\end{figure}

~\\
\textbf{$\psi$-permutation} changes the order of the
  arguments in a \psifun. In a \psifun the order of
  the arguments is significant. Two arguments in a \psifun can
  be permuted if the intersection of their associated predicate in the
  \psifun is empty. An example of such a permutation is shown
  on Figure~\ref{fig:psi_permutation}.

\begin{figure}[h]
\footnotesize
\hfill
\begin{tabular}{llp{3cm}ll}
${\overline{p_2}?}$ & ${a_3 = \texttt{op}3}$              & \ \ \ \  & ${\overline{p_2}?}$ & ${a_3 = \texttt{op}3}$ \\
${p_2?}$ & ${a_2 = \texttt{op}2}$             & \ \ \ \  & ${p_2?}$ & ${a_2 = \texttt{op}2}$ \\
             & ${x_2 = \psi(p_2?a_2, \overline{p_2}?a_3)}$ & \ \ \ \  &              &${x_2 = \psi(\overline{p_2}?a_3, p_2?a_2)}$ \\
\end{tabular}
\caption{$\psi$-permutation of arguments $a_2$ and $a_3$}
\label{fig:psi_permutation}
\end{figure}

~\\
\textbf{$\psi$-promotion} changes one of the predicates used in a
  \psifun by a larger predicate. 
 Promotion must obey the following condition so that the semantics of the \psifun 
 is not altered by the transformation~: consider an operation $ a_0 = \psi(p_1?x_1, ..., p_i?x_i, ..., p_n?x_n)$
promoted into $ a_0 = \psi(p_1?x_1, ..., p_i'?x_i, ..., p_n?x_n)$ with $p_i\subseteq p'_i$, then $p'_i$ must fulfill ${p_i' \subseteq \bigcup_{k=i}^n p_k}$. This is illustrated in Figure~\ref{fig:psi_partial}(c). 
This promotion must also satisfy the properties of \psifuns, and in particular, that the predicate associated with a
variable in a \psifun must be included in or equal to the
predicate on the definition of that variable. This promotion will not
change the predicate of a \psifun, defined as
${\bigcup_{k=1}^n p_k}$.
\begin{figure}[h]
\begin{center}
\footnotesize
\begin{tabular}{llllll}
\iftt ${(p)}$                   &          &                                          &          & \\
\thentt \\
${\ \ \ \ \ a_1 = \texttt{ADD}\ i_1,1;}$ & \ \ \ \  & ${a_1 = \texttt{ADD}\ i_1,1;}$                & \ \ \ \  & ${a_1 = \texttt{ADD}\ i_1,1;}$ \\
\elsett \\
${\ \ \ \ \ a_2 = \texttt{ADD}\ i_1,2;}$ & \ \ \ \  & ${a_2 = \texttt{ADD}\ i_1,2;}$                & \ \ \ \  & ${a_2 = \texttt{ADD}\ i_1,2;}$ \\
${x = \phi(a_1, a_2)}$          & \ \ \ \  & ${x = \psi(p?a_1, \overline{p}?a_2)}$ & \ \ \ \  & ${x = \psi(a_1, \overline{p}?a_2)}$ \\
\\
\multicolumn{2}{l}{\bf (a)\ Phi operation} & \multicolumn{2}{l}{\bf (b)\ Psi\ operation} & \multicolumn{2}{l}{\bf (c)\ Psi\ operation after $\psi$-promotion} \\
\end{tabular}
\caption{$\psi$-SSA for partial predication}
\label{fig:psi_partial}
\end{center}
\end{figure}

The $\psi$-SSA representation can be used on a
  partially predicated architecture, where only a subset of the
  instructions supports a predicate operand.
  Figure~\ref{fig:psi_partial} shows an example where some code with
  control-flow edges was transformed into a linear sequence of
  instructions.
%
Taking the example of an architecture where the \texttt{ADD} operation
cannot be predicated, the \texttt{ADD} operation must be speculated
under the {true} predicate. 
%
On an architecture where the \texttt{ADD} operation can be predicated, it
may also be profitable to perform speculation in order to reduce the
number of predicates on predicated code and to reduce the number of
operations to compute these predicates. 
%
Once speculation has been performed on the definition of a variable
used in a \psifun, the predicate associated with this argument
can be promoted, provided that the semantic of the \psifun is maintained. 



Usually, the first argument of a \psifun can be promoted
under the {true} predicate. Also, when disjoint conditions are
computed, one of them can be promoted to include the other conditions,
usually reducing the number of predicates. A side effect of this
transformation is that it may increase the number of copy instructions
to be generated during the $\psi$-SSA destruction phase, because of
more live-range interference between arguments in a \psifun,
as will be explained in the following section.


\section{Psi-SSA destruction}
\label{sec:Psi_ssa_destruction}

\textbf{3 page}

% Explain what must be done to go out of Psi-SSA. First,
% Psi-normalization must be performed, then live-analysis can be run
% and an interference graph with exact interferences on Psi operations
% can be built. Explain how to repair the interferences and how to
% integrate this algorithm into a standard SSA algorithm.

The SSA destruction phase reverts an SSA representation into a non-SSA
representation. This phase must be adapted to the $\psi$-SSA
representation. The algorithm we present here is derived from the SSA
destruction algorithm from Sreedhar et al., presented in
chapter~\ref{chapter:alternative_ssa_destruction_algorithm}. This algorithm uses
$\psi$-SSA webs to create a conventional $\psi$-SSA
representation. The notion of SSA webs initially defined for $\phi$ is
extended to $\phi$ and $\psi$ operations so as to derive the notion of
conventional $\psi$-SSA ({\em $\psi$-CSSA}) form. A $\psi$-SSA web is
a non empty, minimal, set of variables such that if two variables are
referenced on the same $\phi$ or \psifun then they are in the
same $\psi$-SSA web. The property of the $\psi$-CSSA form is that the
renaming into a single variable of all variables that belong to the
same $\psi$-SSA web, and the removal of the $\psi$ and $\phi$
functions, results in a program with the same semantics as the
original program.

% We define the conventional $\psi$-SSA ({\em $\psi$-CSSA}) form in a
% similar way to the Sreedhar definition of the conventional SSA ({\em
% CSSA}) form. The $\psi$-SSA web definition is an extension of the
% SSA web to include \psifuns.

Now, consider Figure~\ref{fig:psi_interference} to illustrate the
transformations that must be performed to convert a program from a
$\psi$-SSA form into a program in $\psi$-CSSA form.

\begin{figure}
\footnotesize
\subfloat[$\psi$-SSA form]{
\begin{tabular}{ll}
     ${p?}$  & ${b = ...}$         \\
             & ${a = ...}$         \\
             &                     \\
             & ${x = \psi(a,p?b)}$ \\
\\
\end{tabular}
} \hfill
\subfloat[$\psi$-C-SSA form]{
\begin{tabular}{ll}
${p?}$ & ${b = ...}$         \\
       & ${a = ...}$         \\
${p?}$ & ${c = b}$           \\
       & ${x = \psi(a,p?c)}$ \\
\\
\end{tabular}
} \hfill
\subfloat[non-SSA form]{
\begin{tabular}{ll}
${p?}$ & ${b = ...}$ \\
       & ${x = ...}$ \\
${p?}$ & ${x = b}$ \\
       & \\
\\
\end{tabular}
} \hfill
\\
\subfloat[$\psi$-SSA\ form]{
\begin{tabular}{ll}
            & ${a = ...}$ \\
            & ${b = ...}$ \\
            &            \\
            & ${x = \psi(a,p?b)}$ \\
\\
\end{tabular}
} \hfill
\subfloat[$\psi$-C-SSA form]{
\begin{tabular}{ll}
            & ${a = ...}$ \\
            & ${b = ...}$ \\
 ${p?}$     & ${c = b}$ \\
            & ${x = \psi(a,p?c)}$ \\
\\
\end{tabular}
} \hfill
\subfloat[non-SSA form]{
\begin{tabular}{ll}
            & ${x = ...}$ \\
            & ${b = ...}$ \\
 ${p?}$     & ${x = b}$ \\
            & \\
\\
\end{tabular}
} \hfill
\\
\subfloat[$\psi$-SSA form]{
\begin{tabular}{ll}
            & ${a = ...}$ \\
            & \\
${p?}$      & ${b = ...}$ \\
${q?}$      & ${c = ...}$ \\
            & ${x = \psi(a,p?b)}$ \\
            & ${y = \psi(a,q?c)}$ \\
\\
\end{tabular}
} \hfill
\subfloat[$\psi$-C-SSA form]{
\begin{tabular}{ll}
            & ${a = ...}$ \\
            & ${d = a}$ \\
 ${p?}$     & ${b = ...}$ \\
 ${q?}$     & ${c = ...}$ \\
            & ${x = \psi(a,p?b)}$ \\
            & ${y = \psi(d,q?c)}$ \\
\\
\end{tabular}
} \hfill
\subfloat[non-SSA form]{
\begin{tabular}{ll}
            & ${x = ...}$ \\
            & ${y = x}$ \\
 ${p?}$ & ${x = ...}$ \\
 ${q?}$ & ${y = ...}$ \\
     & \\
     & \\
\\
\end{tabular}
} \hfill

\caption{$\psi$-SSA, $\psi$-C-SSA forms and non-SSA form after destruction}
\label{fig:psi_interference}
\end{figure}

%% <<etendre aussi la projection pour la predication partielle ??
%% (Propagation des predicats a travers les instructions non gardes
%% par un algorithm semblable a la sparse constant propagation) >>

Looking at the first example, the dominance order of the definitions
for the variables \textit{a} and \textit{b} differs from their order from
left to right in the \psifun. Such code may appear after a
code motion algorithm has moved the definitions for \textit{a} and
\textit{b} relatively to each other.

%% We said that the semantics of a \psifun is dependent on the
%% order of its arguments, and that the order of the arguments in a
%% \psifun is the order of their definitions in the dominance
%% tree in the original program.

In Figure~\ref{fig:psi_interference}(a) the renaming of the variables
\textit{a}, \textit{b} and \textit{x} into a single variable will not restore
the semantics of the original program. The order in which the
definitions of the variables \textit{a}, \textit{b} and \textit{x} occur must
be corrected. This is done through the introduction of the variable
\textit{c} that is defined as a predicated copy of the variable \textit{b},
and is inserted after the definition of \textit{a}. Now, the renaming of
the variables \textit{a}, \textit{c} and \textit{x} into a single variable will
result in the correct behavior.

In Figure~\ref{fig:psi_interference}(d) the definition of the variable
\textit{b} has been speculated. However, the semantics of the $\psi$
operation is that the variable \textit{x} will only be assigned the value
of \textit{b} when \textit{p} is \textit{true}. A new variable \textit{c} must be
introduced, after the definition of \textit{b} and \textit{p}. This variable
is defined as a predicated copy of the variable \textit{b}. In the
${\psi}$ function, variable \textit{b} is replaced by variable \textit{c},
and the renaming of variables \textit{a}, \textit{c} and \textit{x} into a
single variable will now restore the correct behavior.

In Figure~\ref{fig:psi_interference}(g), the renaming of the variables
\textit{a}, \textit{b}, \textit{c}, \textit{x} and \textit{y} into a single variable
will not give the correct semantics. In fact, the value of \textit{a}
used in the second \psifun would be overridden by the
definition of \textit{b} before the definition of the variable
\textit{c}. Such code will occur after copy folding has been applied on a
$\psi$-SSA representation. We see that the value of \textit{a} has to be
preserved before the definition of \textit{b}, resulting in the code
given for the $\psi$-CSSA representation. Now, the variables \textit{a},
\textit{b} and \textit{x} can be renamed into a single variable, and the
variables \textit{d}, \textit{c} and \textit{y} will be renamed into another
variable, resulting in a program in a non-SSA form with the correct
behavior.

We will now present an algorithm that will transform a program from a
$\psi$-SSA form into its $\psi$-CSSA form. This algorithm is made of
three parts.

\begin{itemize}
\item {\bf Psi-normalize} This part will put all \psifuns
in what we call a {\em normalized} form.
\item {\bf Psi-web} This part will grow $\psi$-SSA webs from $\psi$
  functions, and will introduce repair code where needed.
\item {\bf Phi-web} This part will extend the $\psi$-SSA webs with
  \phifuns. This part is very similar to the SSA destruction
  algorithm presented in chapter~\ref{chapter:alternative_ssa_destruction_algorithm}.
\end{itemize}

We detail now the implementation of each of these three parts.

\subsection{Psi-normalize}

We define the notion of {\em normalized}-$\psi$. When \psifuns
are created during the construction of the $\psi$-SSA representation,
they are naturally built in their normalized form. Later,
transformations are applied to the $\psi$-SSA representation.
Predicated definitions may be moved relatively to each others, and
operation speculation and copy folding may enlarge the domain of the
predicate used on the definition of a variable. These transformations
may cause some \psifuns to be in a non-normalized form.

The normalized form of a \psifun has two characteristics:

\begin{itemize}
\item The order of the arguments in a normalized-\psifun is,
from left to right, equal to the order of their definitions, from top
to bottom, in the control-flow dominance tree.
\item The predicate associated with each argument in a
normalized-\psifun is equal to the predicate used on the
unique definition of this argument.
\end{itemize}

These two characteristics correspond respectively to the two cases
presented in Figure~\ref{fig:psi_interference}(a) and
Figure~\ref{fig:psi_interference}(d).

When some arguments of a \psifun are also defined by $\psi$
functions, the {\em normalized}-$\psi$ characteristics must hold on a
virtual \psifun where $\psi$-inlining has been performed on
these arguments.

%\SubSubSection{PSI-normalize implementation}
\paragraph{PSI-normalize implementation.}

Each \psifun is processed independently. An analysis of the
\psifuns in a top down traversal of the dominator tree
reduces the amount of repair code that is inserted during this pass. We
only detail the algorithm for such a traversal.

For a \psifun ${a_0 = \psi(p_1?a_1, ..., p_i?a_i, ...,
  p_n?a_n)}$, the argument list is processed from left to right. For
each argument ${a_i}$, the predicate ${p_i}$ associated with this argument
in the \psifun and the predicate used on the definition of
this argument are compared. If they are not equal, a new variable
${a'_i}$ is introduced and is initialized at the highest point in the
dominator tree after the definition of ${a_i}$ and ${p_i}$. ${a'_i}$ is
defined by the operation ${p_i? a'_i = a_i}$. Then, ${a_i}$ is
replaced by ${a'_i}$ in the \psifun.

Then, we consider the dominance order of the definition for ${a_i}$,
with the definition for ${a_{i-1}}$. When ${a_i}$ is defined on a
\psifun, we recursively look for the definition of the first
argument of this \psifun, until a definition on a non-$\psi$
function is found. Now, if the definition we found for ${a_i}$
dominates the definition for ${a_{i-1}}$, some correction is needed.

If the predicates ${p_{i-1}}$ and ${p_i})$ are disjoint, a
$\psi$-permutation can be applied between ${a_{i-1}}$ and
${a_i}$, so as to reflect into the \psifun the actual
dominance order of the definitions of ${a_{i-1}}$ and ${a_i}$.

If $\psi$-permutation cannot be applied, a new variable ${a'_i}$
is created for repair. ${a'_i}$ is defined by the operation
${p_i? a'_i = a_i}$. This copy operation is inserted at the highest
point that is dominated by the definitions of ${a_{i-1}}$ and
${a_i}$.
\footnote{When ${a_i}$ is defined by a \psifun, its
  definition may appear after the definition for ${a_{i-1}}$,
  although the non-$\psi$ definition for ${a_i}$ appears before
  the definition for ${a_{i-1}}$.}
Then, ${a_i}$ is replaced in the \psifun by ${a'_i}$.

The algorithm continues with the argument ${a_{i+1}}$, until all
arguments of the \psifun are processed. When all arguments
are processed, the $\psi$ is in its normalized form. When all $\psi$
functions are processed, the function will contain only
normalized-\psifuns.

%% The top-down traversal of the dominator tree will ensure that when a
%% variable in a \psifun is defined by another \psifun,
%% this \psifun has already been analyzed and put in its
%% normalized form. Thus the definition of its first variable already
%% dominates the definitions for the other arguments of the $\psi$
%% function.

\subsection{Psi-web}

In this pass, we repair the \psifuns when variables cannot be
put into the same $\psi$-SSA web, because their live ranges
interfere. This case corresponds to the example presented in
Figure~\ref{fig:psi_interference}(g).

In the same way as there is a specific point of use for arguments on
\phifuns for liveness analysis, we give a definition of the
actual point of use of arguments on \psifuns for liveness
analysis. With this definition, liveness analysis will be computed
accurately and an interference graph can be built.

%\SubSubSection{Liveness and interferences in Psi-SSA}
\paragraph{Liveness and interferences in Psi-SSA.}
We have already shown in Figure~\ref{fig:psi_interference}(g) that
repair code may be needed so that the arguments and definition of a
\psifun can be renamed into a single name. We first give a
definition of the point of use of the arguments in a \psifun
such that liveness analysis can be accurately computed. With this
liveness, the cases where repair code is needed can be easily and
accurately detected by observing that live-ranges for variables in a
\psifun overlap.

Consider the code in Figure~\ref{fig:psi_ccond} (b). Instead of using
a representation with \psifuns, predicated definitions have
been modified to make a reference to the value the predicated
definition will have in case the predicate is \textit{false}. We use in this
example the notation of the C conditional operator
${x = cond\ ?\ exp1 : exp2}$. Each of the predicated definitions make an
explicit use of the variable immediately to its left in the argument
list of the original \psifun from Figure~\ref{fig:psi_ccond}
(a). We can see that a renaming of the variables \textit{a}, \textit{b},
\textit{c} and \textit{x} into a single representative name will still
compute the same value for the variable \textit{x}. Note that this
transformation can only be performed on normalized \psifuns,
since the definition of an argument must be dominated by the
definition of the argument immediately at its left in the argument
list of the \psifun, and the same predicate must be used on the
 definition of an argument and with this argument in the $\psi$ operation.
Using this equivalence for the
representation of a \psifun, we now give a definition of the
point of use for the arguments of a \psifun.

{\bf Definition} {\em We say that the point of use of an argument in a
  normalized \psifun occurs at the point of definition of the
  argument immediately at its right in the argument list of the $\psi$
  function. For the last argument of the \psifun, the point of
  use occurs at the \psifun itself. }

\begin{figure}
\begin{center}
\footnotesize
\begin{tabular}{llll}
           & ${a = op1}$ & \ \ \ \ & ${a = op1}$ \\
${p?}$ & ${b = op2}$ & \ \ \ \ & ${b = p\ ?\ op2\ :\ a}$ \\
${q?}$ & ${c = op3}$ & \ \ \ \ & ${c = q\ ?\ op3\ :\ b}$ \\
           & ${x = \psi(a,p?b,q?c)}$ & \ \ \ \ & ${x = c}$ \\
\\
\multicolumn{2}{l}{{\bf (a)\ Psi-SSA form}} & \ \ \ \ & {{\bf (b)\ C conditional form}}
\end{tabular}
\caption{\psifuns and C conditional operations equivalence}
\label{fig:psi_ccond}
\end{center}
\end{figure}

Given this definition of point of use of $\psi$ arguments, and using
the usual point of use of $\phi$ arguments, a traditional liveness
analysis can be run. Then an interference graph can be built to
collect the interferences between variables involved in $\psi$ or
\phifuns. For the construction of the interference graph, an
interference between two variables that are defined on disjoint
predicates can be ignored.

%\SubSubSection{Repairing interferences on $\psi$ operations}
\paragraph{Repairing interferences on \psifuns.}
We now present an algorithm that creates $\psi$-SSA webs from $\psi$
functions such that there is no interference between two variables in
the same $\psi$-SSA web.

First, the $\psi$-SSA webs are initialized such that each variable in
the $\psi$-SSA representation belongs to its own $\psi$-SSA web. Then,
\psifuns are processed one at a time, in no specific order. A
pseudo-code of this algorithm is given in
Figure~\ref{fig:pseudo_psi_repair}.

The analysis of a \psifun starts by setting the current
$\psi$-SSA web to the $\psi$-SSA web of the result of the $\psi$
function. Then, the arguments of the \psifun are processed
from right to left. The $\psi$-SSA web for an argument can be merged
into the current $\psi$-SSA web if these two $\psi$-SSA webs do not
interfere. Two $\psi$-SSA webs interfere if at least one variable in
the first $\psi$-SSA web interferes with at least one variable in the
other one.

If the $\psi$-SSA web for an argument ${a_i}$ does not interfere
with the current $\psi$-SSA web, then the two $\psi$-SSA webs are
merged. Otherwise, the $\psi$-SSA web for the argument ${a_i}$
cannot be merged with the current $\psi$-SSA web, and repair code is
needed. A new variable, ${a'_i}$, is created and is initialized
with a predicated copy ${p_i? a'_i = a_i}$, inserted just below
the definition for ${a_i}$. The current argument ${a_i}$ in
the \psifun is replaced by the new variable ${a'_i}$. The
interference graph is updated with an interference between ${a_i}$
and ${a'_i}$. Also, conservatively, ${a'_i}$ is considered to
be interfering with all the variables ${a_i}$ interfere with,
except with those variables in the current $\psi$-SSA web. The
conservative update of the interference graph may increase the number
of copies generated during the conversion to the $\psi$-CSSA form.

Then the algorithm proceeds with the next argument on the left until
all arguments are processed.

\begin{algorithm}[h]
\Begin{
 $psiWeb \leftarrow SSAWeb\_get(psiOp->result())$ \;
 \ForEach{$psiOpnd \leftarrow psiOp->opnd(i)$, from right to left}{
  $psiOpndWeb \leftarrow SSAWeb\_get(psiOpnd)$ \;
  \If{IGraph\_interferes(psiWeb, psiOpndWeb)}{
   \Let{newOpnd be a freshly created variable} \;
   insert copy $newOpnd \leftarrow psiOpnd$ under predicate $psiOp->predicate(i)$ after $psiOpnd->defOp()$ \;
   $psiOp->opnd(i) \leftarrow newOpnd$ \;
   $psiOpndWeb \leftarrow SSAWeb\_get(newOpnd)$ \;
   IGraph\_addInterference(newOpnd, psiOpnd) \;
   \ForEach{var in IGraph\_interferenceSet(psiOpnd)}{
    \If{!SSAWeb\_contain(psiWeb, var)}{
     IGraph\_addInterference(newOpnd, var) \;
    }
   }
   $psiWeb \leftarrow SSAWeb\_union(psiWeb, psiOpndWeb)$ \;
  }
 }
}
\caption{Merging $\psi$-SSA webs on a \psifun}
\label{fig:pseudo_psi_repair}
\end{algorithm}


% Some comments on an exact interference graph update ??

Consider the code in Figure~\ref{fig:live_interference} to see how
this algorithm works. The liveness on the \psifun creates a
live-range for variable \textit{a} that extends down to the definition of
\textit{b}, but not further down. Thus, the variable \textit{a} does not
interfere with the variables \textit{b}, \textit{c} or \textit{x}. The
live-range for variable \textit{b} extends down to its use in the
definition of variable \textit{d}. This live-range interferes with the
variables \textit{c} and \textit{x}. The live-range for variable \textit{c}
extends down to its use in the \psifun that defines the
variable \textit{x}.

At the beginning of the processing on the \psifun ${x =
  \psi(p?a,q?b,r?c)}$, all variables belong to their own $\psi$-SSA
web. The current $\psi$-SSA web is set to the $\psi$-SSA web of the
result, ${\{x\}}$. Then the argument list is processed from right
to left. Variable \textit{c} does not interfere with current $\psi$-SSA
web ${\{x\}}$, they can be merged together, resulting in a current
$\psi$-SSA web ${\{x, c\}}$. Then, variable \textit{b} is
processed. Since it interferes with both \textit{x} and \textit{c},
repair code is needed. A variable \textit{b'} is created, and is
initialized just below the definition for \textit{b}, as a predicated
copy of \textit{b}. The interference graph is updated, only an
interference between \textit{b'} and \textit{b} is added. The current
$\psi$-SSA web now becomes ${\{x, b', c\}}$. Then variable \textit{a}
 is processed and inserted into the current $\psi$-SSA web. The
final code after SSA destruction is shown in
Figure~\ref{fig:live_interference}(c).

\begin{figure}
\begin{center}
\footnotesize
\begin{tabular}{llllll}
${p?}$ & ${a = ...}$              & ${p?}$ & ${a = ...}$                 & ${p?}$ & ${x = ...}$\\
${q?}$ & ${b = ...}$              & ${q?}$ & ${b = ...}$                 & ${q?}$ & ${b = ...}$\\
           &                              & ${q?}$ & ${b' = b}$                  & ${q?}$ & ${x = b}$\\
${r?}$ & ${c = ...}$              & ${r?}$ & ${c = ...}$                 & ${r?}$ & ${x = ...}$ \\
           & ${x = \psi(p?a,q?b,r?c)}$ &            & ${x = \psi(p?a,q?b',r?c)}$   &            & \\
${s?}$ & ${d = b+1}$              & ${s?}$ & ${d = b+1}$                 & ${s?}$ & ${d = b+1}$ \\
\\
\multicolumn{2}{l}{\bf (a)\ before\ $\psi$\ processing} & \multicolumn{2}{l}{\bf (b)\ after $\psi$\ processing} & \multicolumn{2}{l}{\bf (c)\ after $\psi$\ renaming} \\
\end{tabular}
\caption{Elimination of $\psi$ live-interference}
\label{fig:live_interference}
\end{center}
\end{figure}

\subsection{Phi-web}

When all \psifuns are processed, the $\psi$-SSA webs built
from \psifuns are extended to include the variables in $\phi$
functions. In this part, the algorithm presented in
chapter~\ref{chapter:alternative_ssa_destruction_algorithm} is used, with a few
modifications.

The first modification is that the $\psi$-SSA webs must not be
initialized at the beginning of this process. They have already been
initialized at the beginning of the $\psi$-web step, and were extended
during the processing of \psifuns. These webs will be extended
now with \phifuns during this step.

The second modification is that the live-analysis run for this part
must take into account the particular point of use of arguments on
\psifuns.

All other parts of the SSA destruction algorithm from
chapter~\ref{chapter:alternative_ssa_destruction_algorithm}, to convert an SSA
representation into a CSSA form, are unchanged.

We have described a complete algorithm to convert a $\psi$-SSA
representation into a $\psi$-CSSA representation. The final step to
convert the code into a non-SSA form is a simple renaming of all the
variables in the same $\psi$-SSA web into a representative name. The
$\psi$ and \phifuns are then removed.

%% \paragraph{Interference with the result of a \psifun.}

%% When the live-range for an argument of a \psifun overlaps
%% with the live-range of the variable defined by the \psifun,
%% this interference can be ignored. Actually, there are two cases to
%% consider:

%% \begin{itemize}
%% \item If the argument is not the last one in the \psifun, and
%% its live-range overlaps with the live-range of the definition of the
%% \psifun, then this live-range also overlaps with the
%% live-range of the last argument. Thus this interference will already
%% be detected and repaired.

%% \item If the argument is the last one of the \psifun, then
%% the value of the \psifun is the value of this last argument,
%% and this argument and the definition will be renamed into the same
%% variable out of the SSA representation. Thus, there is no need to
%% introduce a copy here.
%% \end{itemize}


\section{Additional reading}

In this chapter we mainly described the $psi$-SSA representation and we detailed specific transformations that can be performed thanks to this representation. More details on the implementation of the $psi$-SSA algorithms, and figures on the benefits of this representation, can be found in \cite{Stoutchinin:2001:MICRO} and \cite{Ferriere:2007:SCOPES}.

We mentioned in this chapter that a number of classical SSA-based algorithm can be easily adapted to the $psi$-SSA representation, usually by just adpating the rules on the \phifuns to the \psifuns. Among these algorithm, we can mention the constant propagation algorithm described in~\cite{WZ91}, dead code elimination~\cite{morgan98}, global value numbering~\cite{Cli95}, partial redundancy elimination~\cite{CCK+97} and induction variable analysis~\cite{Wolfe92} which have already been implemented into a $psi$-SSA framework.

There are also other SSA representations that can handle predicated instruction, of which is the Predicated SSA representation~\cite{Carter:PACT99}. This representation is targeted at very low level optimization to improved operation scheduling in presence of predicated instructions. Another representation is the Gated SSA form, presented in chapter~\ref{chapter:vsdg}.
