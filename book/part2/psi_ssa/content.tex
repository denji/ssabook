\chapter{Psi-SSA Form \Author{F. de Ferri\`ere}}
\inputprogress
\label{chapter:psi_ssa}

\section{Overview}

% Explain why SSA renaming cannot be applied on predicated definitions. 

% The $\psi$-SSA representation was developed to extend the SSA
% representation with support for predicated operations.

In the SSA representation, each definition of a variable is given a
unique name\index{single definition property}, and new pseudo definitions are introduced on \phifuns to merge values coming from different control flow paths. An
example is given figure~\ref{fig:op_ssa}(b). Each definition is an
unconditional definition, and the value of a variable is the value of
the expression on the unique assignment to this variable. This
essential property of the SSA representation does not any longer hold
when definitions may be conditionally executed\index{predicated execution}. When a variable is defined by a predicated operation, the value of the variable
will or will not be modified depending on the value of a guard
register. As a result, the value of the variable after the predicated
operation is either the value of the expression on the assignment if
the predicate is true, or the value the variable had before this
operation if the predicate is false. This is represented in
figure~\ref{fig:op_ssa}(c) where we use the notation $p\cond a = \texttt{op}$ to indicate that an operation $a = \texttt{op}$ is executed only if predicate $p$ is true\index{guard}\index{predicate}, and is ignored otherwise. We will also use the notation $\overline{{p}}$ to refer to the complement of predicate \textit{p}.
The goal of the $\psi$-SSA form advocated in this chapter is to express these conditional definitions while keeping the static single assignment property.

\begin{figure}
\footnotesize
\subfloat[non-SSA]{
\begin{tabular}{l}
${a = \texttt{op1}};$ \\
\iftt ${(p)}$\\
\thentt\\
$\ \ \ \ a = \texttt{op2};$\\
\\
${\ \ = a}$ \\
\\
\end{tabular}
} \hfill
\subfloat[SSA]{
\begin{tabular}{l}
 ${a}_1 = \texttt{op1};$ \\
 \iftt ${(p)}$      \\
 \thentt\\
$\ \ \ \ a_2 = \texttt{op2};$ \\
${a}_3 = \phi({a}_1, {a}_2)$ \\
${\ \ = a}_3$            \\
\\
\end{tabular}
}\hfill
\subfloat[With predication]{
\begin{tabular}{lp{2cm}}
            & ${a}_1 = \texttt{op1};$\\
&\\
&\\
 ${p?}$ & ${a}_2 = \texttt{op2};$ \\
&\\
            & ${\ = a_{??}}$ \\
\\
\end{tabular}
}\hfill
\subfloat[$\psi$-SSA]{
\begin{tabular}{ll}
            & ${a}_1 = \texttt{op1};$\\
&\\
&\\
 ${p?}$ & ${a}_2 = \texttt{op2};$ \\
& $a_3=\psi(a_1,p?a_2)$\\
            & ${\ = a_3}$ \\
\\
\end{tabular}
}
\caption{SSA representation}
\label{fig:op_ssa}
\end{figure}

\section{Definition and Construction}


% Gives the semantics of the PSI function, doing the parallel with PHI
% function before if-conversion. Explain the relation between the
% predicates on the definition and the predicates in the PSI. Explain
% how a PSI function is executed.

Predicated operations are used to convert control flow regions into
straight-line code. Predicated operations may be used by the intermediate
representation in an early stage of the compilation process as a result of inlining intrinsic functions. Later on, the compiler may
also generate predicated operations through if-conversion optimizations
as described in Chapter~\ref{chapter:if_conversion}.


In figure~\ref{fig:op_ssa}(c), the use of \textit{a} on the last
instruction refers to the variable ${a_1}$ if \textit{p} is false, or
to the variable ${a_2}$ if \textit{p} is true. These multiple
reaching definitions on the use of \textit{a} cannot be represented by
the standard SSA representation.
%
One possible representation would be to use the Gated-SSA form\index{Gated-SSA form},
presented in Chapter~\ref{chapter:vsdg}. In such a representation, the
\phifun would be augmented with the predicate \textit{p} to tell
which value between ${a_1}$ and ${a_2}$ is to be
considered. However, Gated-SSA is a completely different intermediate
representation where the control flow is no longer represented. This
representation is more suited for program interpretation than for optimizations at code generation level as addressed in this chapter.
%
Another possible representation would be to add a reference to ${a_1}$
 on the definition of ${a_2}$. $p\cond a_2=\texttt{op2} {\color{gray}~|~a_1}$ 
would have the following semantic: ${a_2}$ takes the value computed by $\texttt{op2}$ if $p$ is true, or holds
the value of ${a_1}$ if \textit{p} is {false}. The use of \textit{a} on the last instruction of Figure~\ref{fig:op_ssa}(c)
would now refer to the variable ${a_2}$, which holds the correct
value. The drawback of this representation is that it adds
dependencies\index{dependence, flow-} between operations (here a flow dependence from \texttt{op1} to \texttt{op2}), which would prevent code reordering
for scheduling.

Our solution is presented in figure~\ref{fig:op_ssa}(d). The \phifun of the SSA code with control flow
is ``replaced'' by a \psifun{}\index{\psifun} on the corresponding predicated code, with information on the
predicate associated with each argument. This representation is
adapted to code optimization and code generation on a low-level
intermediate representation.\index{back-end, compiler}
%
A \psifun ${a_0 = \psi({p}_1?{a}_1,\ \dots,\ {p}_i?{a}_i,\
  \dots,\ {p}_n?{a}_n)}$ defines one variable, ${a_0}$,
and takes a variable number of arguments ${a_i}$; each
argument ${a_i}$ is associated with a predicate ${p_i}$. In
the notation, the predicate ${p_i}$ will be omitted if
${p_i} \equiv \textrm{true}$.\index{guard}\index{gate}\index{predicate}
\newpage
A \psifun has the following properties:
\begin{itemize}

\item{\emph{It is an operation}}~: A \psifun is a regular operation. It
  can occur at any location in a basic block where a regular operation
  is valid. Each argument ${a_i}$, and each predicate ${p_i}$,
  must be dominated by its definition.

\item{\emph{It is predicated}}~: A \psifun is a predicated
  operation, under the predicate ${\bigcup_{k=1}^n p_k}$,
  although this predicate is not explicit in the representation.

\item{\emph{It has an ordered list of arguments}}~: The order of the
  arguments in a \psifun is significant. A \psifun is
  evaluated from left to right. The value of a \psifun is the
  value of the right most argument whose predicate evaluates to true.

\item{\emph{Rule on predicates}}~: The predicate ${p_i}$ associated
  with the argument ${a_i}$ in a \psifun must be included
  in or equal to the predicate on the definition of the variable ${a_i}$.
In other words, for the code $q\cond {a}_i = \texttt{op}$;  ${a}_0 = {\psi}(\dots,\ {p}_i?{a}_i,\dots)$, we must have 
${p}_i \subseteq {q}$ (or $p_i \Rightarrow q$).

\end{itemize}

\begin{figure}[h]
\begin{center}
\footnotesize
\hfill
\subfloat[control flow code]{
\begin{tabular}{p{3cm}}
\iftt ${(p)}$\\
\thentt   \\
${\ \ \ \ \ a_1 = 1;}$\\
\elsett \\
${\ \ \ \ \     a_2 = -1;}$\\
${x_1 = \phi(a_1, a_2)}$\\
\iftt ${(q)}$\\
\thentt\\
${\ \ \ \ \ a_3 = 0;}$\\
${x_2 = \phi(x_1, a_3)}$\\
\end{tabular}
} \hfill
\subfloat[Predicated code]{
\begin{tabular}{lp{3cm}}
&\\
& \\
 ${p?}$ & ${a_1 = 1;}$ \\
\\
 ${\overline{p}?}$ & ${a_2 = -1;}$ \\
& ${x_1 = \psi(p?a_1, \overline{p}?a_2)}$ \\
\\
\\
 ${q?}$ & ${a_3 = 0;}$ \\
& ${x_2 = \psi(p?a_1, \overline{p}?a_2, q?a_3)}$ \\
\end{tabular}
}
\hfill
\caption{$\psi$-SSA with non-disjoint predicates}
\label{fig:non_disjoint_pred}
\end{center}
\end{figure}

A \psifun can represent cases where variables are defined on arbitrary independent
predicates such as $p$ and $q$ in the example of Figure~\ref{fig:non_disjoint_pred}~: For this example, during the SSA
construction a unique variable \textit{a} was renamed into the variables
${a_1}$, ${a_2}$ and ${a_3}$ and the variables ${x_1}$
and ${x_2}$ were introduced to merge values coming from different
control flow paths. In the control flow version of the code, there is a
control-dependence\index{dependence, control-} between the basic-block that defines ${x_1}$ and the operation that defines ${a_3}$, which means
the definition of ${a_3}$ must be executed after the value for
${x_1}$ has been computed. In the predicated form of this example,
there is no longer any control dependencies between the definitions of
${a_1}$, ${a_2}$ and ${a_3}$. A compiler transformation
can now freely move these definitions independently of each other,
which may allow more optimizations to be performed on this
code. However, the semantics of the original code requires that the
definition of ${a_3}$ occurs after the definitions of ${a_1}$
and ${a_2}$. The order of the arguments in a \psifun gives
information on the original order of the definitions. We take the
convention that the order of the arguments in a \psifun is,
from left to right, equal to the original order of their definitions,
from top to bottom, in the control flow dominance tree of the program
in a non-SSA representation. This information is needed to maintain
the correct semantics of the code during transformations of the
$\psi$-SSA representation and to revert the code back to a non
$\psi$-SSA representation.


The construction of the $\psi$-SSA representation is a small\index{construction, of $\psi$-SSA}
modification on the standard algorithm to built an SSA representation (see Section~\ref{sec:classical_construction}).
%
The insertion of \psifuns is performed during the SSA renaming\index{renaming, of variables}
phase.
%
During the SSA renaming phase, basic blocks are processed in their
dominance order, and operations in each basic block are scanned from
top to bottom. On an operation, for each predicated definition of a
variable, a new \psifun will be inserted just after the
operation~: Consider the definition of a variable \textit{x} under predicate
${p_2}$ ($p_2\cond x= \texttt{op}$); suppose ${x_1}$ is the current version of $x$ before
to proceeding \texttt{op}, and that $x_1$ is defined through predicate $p_1$ (possibly true); after renaming $x$ into a freshly created version, say $x_2$, a \psifun of the form ${x = \psi(p_1?x_1,
  p_2?x)}$, is inserted right after \texttt{op}. 
Then renaming of this new operation proceeds. The first argument of
the \psifun is already renamed and thus is not modified. The
second argument is renamed into the current version of \textit{x}
which is ${x_2}$. On the definition of the \psifun, the
variable \textit{x} is given a new name, ${x_3}$, which becomes the
current version for further references to the \textit{x} variable. This
insertion and renaming of a \psifun is shown on
Figure~\ref{fig:psi_ssa_construct}.

\begin{figure}[h]
\footnotesize
\subfloat[Initial]{
\begin{tabular}{ll}
${p_2?}$ & ${x = \texttt{op}}$\\
\\
\end{tabular}
}\hfill
\subfloat[$\psi$-insertion]{
\begin{tabular}{ll}
 ${p_2?}$ & ${x = \texttt{op}}$ \\
           & ${x = \psi(p_1?x_1, p_2?x)}$ \\
\end{tabular}
} \hfill
\subfloat[\texttt{op}-renaming]{
\begin{tabular}{ll}
 ${p_2?}$ & ${x_2 = \texttt{op}}$ \\
           & ${x = \psi(p_1?x_1, p_2?x)}$ \\
\end{tabular}
} \hfill
\subfloat[$\psi$-renaming]{
\begin{tabular}{ll}
 ${p_2?}$ & ${x_2 = \texttt{op}}$\\
           & ${x_3 = \psi(p_1?x_1, p_2?x_2)}$ \\
\end{tabular}
}
\caption{Construction and renaming of $\psi$-SSA}
\label{fig:psi_ssa_construct}
\end{figure}


\psifuns can also be introduced in an SSA representation by
applying an if-conversion transformation, such as the one that is
described in Chapter~\ref{chapter:if_conversion}.\index{if-conversion} Local transformations
on control flow patterns can also require to replace \phifuns
by \psifuns.

\section{SSA algorithms}


% Explain how standard SSA algorithm can be adapted to the Psi-SSA
% form: Predicated definitions are now seen as non-predicated ones,
% and a semantics, similar to the similar of PHI functions, must be
% defined for PSI functions.

With this definition of the $\psi$-SSA representation, implicit data flow links\index{def-use chains} to predicated operations are now explicitly expressed through \psifuns. Usual algorithms that perform
optimizations or transformations on the SSA representation can now be
easily adapted to the $\psi$-SSA representation, without compromising
the efficiency of the transformations performed. Actually, within the
$\psi$-SSA representation, predicated definitions behave exactly the
same as non predicated ones for optimizations on the SSA
representation. Only the \psifuns have to be treated in a
specific way. As an example, the classical constant propagation\index{constant propagation}
algorithm under SSA can be easily adapted to the $\psi$-SSA
representation. In this algorithm, the only modification is that
\psifuns have to be handled with the same rules as the \phifuns. Other algorithms such as dead code elimination\index{dead code elimination}(see Chapter~\ref{chapter:classical_construction_algorithm}), global
value numbering\index{global vale numbering}, partial redundancy elimination\index{partial redundancy elimination} (see Chapter~\ref{chapter:pre_not_helped}), and induction
variable analysis\index{induction variable recognition} (see Chapter~\ref{chapter:loop_tree}), are examples of algorithm that can easily be adapted
to this representation with minor efforts.

\section{Psi-SSA algorithms}


% Special transformations can be applied on Psi-SSA, which allows to
% optimize predicated code. Explain on an example what are the uses of
% inlining, reduction, projection and predicate promotion.

In addition to standard algorithms that can be applied to \psifuns and predicated code, a number of specific transformations
can be performed on the \psifuns, namely $\psi$-inlining,
$\psi$-reduction, $\psi$-projection, $\psi$-permutation and
$\psi$-promotion. For a \psifun ${a_0 = \psi(p_1?a_1, ...,
  p_i?a_i, ..., p_n?a_n)}$, those transformations are defined as
follows:

~\\
{\bf $\psi$-inlining}\index{ $\psi$-inlining} recursively replaces in a $\psi$
  function an argument ${a_i}$ that is defined on another $\psi$
  function by the arguments of this other \psifun. The
  predicate ${p_i}$ associated with argument ${a_i}$ will be distributed
  with an \texttt{and} operation over the predicates associated with the
  inlined arguments. This is shown in figure~\ref{fig:psi_inlining}.
\begin{figure}[h]
\begin{center}
\footnotesize\hfill
{
\begin{tabular}{ll}
             & ${a_1 = \texttt{op}1}$  \\
${p_2?}$ & ${a_2 = \texttt{op}2}$        \\
             & ${x_1 = \psi(a_1,\ p_2?a_2)}$\\
${p_3?}$ & ${a_3 = \texttt{op}3}$             \\
             & ${x_2 = \psi(p_1?x_1,\ p_3?a_3)}$ \\
\end{tabular}
} \hfill
{
\begin{tabular}{ll}
                & ${a_1 = \texttt{op}1}$ \\
 ${p_2?}$ & ${a_2 = \texttt{op}2}$ \\
           & \color{gray} $x_1 = \psi(a_1,\ p_2?a_2)$ // dead \\
 ${p_3?}$ & ${a_3 = \texttt{op}3}$ \\
         & ${x_2 = \psi(p_1?a_1,\ p_1\wedge p_2?a_2,\ p_3?a_3)}$ \\
\end{tabular}
}
\caption{$\psi$-inlining of the definition of $x_1$}
\label{fig:psi_inlining}
\end{center}
\end{figure}

~\\
{\bf $\psi$-reduction}\index{$\psi$-reduction} removes from a \psifun an
  argument ${a_i}$ whose value will always be overridden by arguments on
  its right in the argument list. An argument ${a_i}$ associated
  with predicate ${p_i}$ can be removed if ${p_i \subseteq
    \bigcup_{k=i+1}^n p_k}$. This can be illustrated by the example of
  Figure~\ref{fig:psi_reduction}.



\begin{figure}[h]
\begin{center}
\footnotesize
\hfill
\begin{tabular}{ll}
             & ${a_1 = \texttt{op}1}$  \\
${p_2?}$ & ${a_2 = \texttt{op}2}$        \\
${\overline{p_2}?}$ & ${a_3 = \texttt{op}3}$ \\
             & ${x_2 = \psi(a_1, p_2?a_2, \overline{p_2}?a_3)}$\\
\end{tabular}\hfill
\begin{tabular}{ll}
      & ${a_1 = \texttt{op}1}$ \\
 ${p_2?}$ & ${a_2 = \texttt{op}2}$ \\
 ${\overline{p_2}?}$ & ${a_3 = \texttt{op}3}$ \\
        &${x_2 = \psi(p_2?a_2, \overline{p_2}?a_3)}$ \\
\end{tabular}
\caption{$\psi$-reduction. The first argument  $a_1$ of the \psifun can safely be removed}
\label{fig:psi_reduction}
\end{center}
\end{figure}

\textbf{$\psi$-projection}\index{$\psi$-projection}\index{predication} creates from a \psifun a
  new \psifun on a restricted predicate say $p$.  In this new \psifun, an argument ${a_i}$ initially guarded by $p_i$ shall be guarded by the conjunction $p_i\wedge p$. If $p_i$ is known to be disjoint with $p$, $a_i$ actually
  contributes no value to the \psifun and thus can be
  removed. $\psi$-projection on predicate $p$ is usually performed when the result of a \psifun is used in an operation predicated by $p$. This is illustrated in Figure~\ref{fig:psi_projection}.

\begin{figure}[h]
\footnotesize
\hfill
\begin{tabular}{llp{3cm}ll}
${p_2?}$ & ${a_2 = \texttt{op}2}$             & \ \ \ \ \ \ \ \  & ${p_2?}$ & ${a_2 = \texttt{op}2}$ \\
${\overline{p_2}?}$ & ${a_3 = \texttt{op}3}$              & \ \ \ \  & ${\overline{p_2}?}$ & ${a_3 = \texttt{op}3}$ \\
             & ${x_2 = \psi(p_2?a_2, \overline{p_2}?a_3)}$ & \ \ \ \  &              &${x_2 = \psi(p_2?a_2, \overline{p_2}?a_3)}$ \\
             &                               & \ \ \ \  &              & ${x_3 = \psi(p_2?a_2)}$ \\
${p_2?}$ & ${y_1 = x_2}$              & \ \ \ \  & ${p_2?}$ & ${y_1 = x_3}$ \\
\end{tabular}
\caption{$\psi$-projection of $x_2$ on $p_2$. Second argument $a_3$ can be removed.}
\label{fig:psi_projection}
\end{figure}

~\\
\textbf{$\psi$-permutation}\index{$\psi$-permutation} changes the order of the
  arguments in a \psifun. In a \psifun the order of
  the arguments is significant. Two arguments in a \psifun can
  be permuted if the intersection of their associated predicate in the
  \psifun is empty. An example of such a permutation is shown
  on Figure~\ref{fig:psi_permutation}.

\begin{figure}[h]
\footnotesize
\hfill
\begin{tabular}{llp{3cm}ll}
${\overline{p_2}?}$ & ${a_3 = \texttt{op}3}$              & \ \ \ \  & ${\overline{p_2}?}$ & ${a_3 = \texttt{op}3}$ \\
${p_2?}$ & ${a_2 = \texttt{op}2}$             & \ \ \ \  & ${p_2?}$ & ${a_2 = \texttt{op}2}$ \\
             & ${x_2 = \psi(p_2?a_2, \overline{p_2}?a_3)}$ & \ \ \ \  &              &${x_2 = \psi(\overline{p_2}?a_3, p_2?a_2)}$ \\
\end{tabular}
\caption{$\psi$-permutation of arguments $a_2$ and $a_3$}
\label{fig:psi_permutation}
\end{figure}

~\\
\textbf{$\psi$-promotion}\index{$\psi$-promotion}\index{speculation} changes one of the predicates used in a
  \psifun by a larger predicate. 
 Promotion must obey the following condition so that the semantics of the \psifun 
 is not altered by the transformation~: consider an operation $ a_0 = \psi(p_1?x_1, ..., p_i?x_i, ..., p_n?x_n)$
promoted into $ a_0 = \psi(p_1?x_1, ..., p_i'?x_i, ..., p_n?x_n)$ with $p_i\subseteq p'_i$, then $p'_i$ must fulfill 
\begin{equation}
\left(p_i' \backslash \bigcup_{k=i}^n p_k\right) \cap \bigcup_{k=1}^{i-1} p_k=\emptyset \label{eq:psi_ssa:prom}
\end{equation}
where $p_i' \backslash \bigcup_{k=i}^n p_k$ corresponds to the possible increase of the predicate of the \psifun, $\bigcup_{k=1}^{n} p_k$. 
This promotion must also satisfy the properties of \psifuns, and in particular, that the predicate associated with a
variable in a \psifun must be included in or equal to the
predicate on the definition of that variable (which itself can be a \psifun). A simple $\psi$-promotion is illustrated in Figure~\ref{fig:psi_partial}(c). 
\begin{figure}[h]
\begin{center}
\footnotesize
\hfill
\subfloat[control flow]{
\begin{tabular}{ll}
\iftt ${(p)}$               \\
\thentt \\
${\ \ \ \ \ a_1 = \texttt{ADD}\ i_1,1;}$\\
\elsett \\
${\ \ \ \ \ a_2 = \texttt{ADD}\ i_1,2;}$\\
${x = \phi(a_1, a_2)}$  \\
\\
\end{tabular}} \hfill
\subfloat[$\psi$-SSA]{
\begin{tabular}{ll}
\\
\\
  & ${a_1 = \texttt{ADD}\ i_1,1;}$ \\
 \\
  & ${a_2 = \texttt{ADD}\ i_1,2;}$ \\
 & ${x = \psi(p?a_1, \overline{p}?a_2)}$ \\
\\
\end{tabular}}\hfill
\subfloat[after $\psi$-promotion]{
\begin{tabular}{p{2.5cm}}
\\
\\
${a_1 = \texttt{ADD}\ i_1,1;}$ \\
 \\
 ${a_2 = \texttt{ADD}\ i_1,2;}$ \\
 ${x = \psi(a_1, \overline{p}?a_2)}$ \\
\\
\end{tabular}
}
\caption{$\psi$-SSA for partial predication. $\psi$-promotion of argument $a_1$}
\label{fig:psi_partial}
\end{center}
\end{figure}

The $\psi$-SSA representation can be used on a
  partially predicated architecture\index{predication, partial}, where only a subset of the
  instructions supports a predicate operand.
  Figure~\ref{fig:psi_partial} shows an example where some code with
  control flow edges was transformed into a linear sequence of
  instructions.
%
Taking the example of an architecture where the \texttt{ADD} operation
cannot be predicated, the \texttt{ADD} operation must be speculated\index{speculation}
under the {true} predicate. 
%
On an architecture where the \texttt{ADD} operation can be predicated, it
may also be profitable to perform speculation in order to reduce the
number of predicates on predicated code and to reduce the number of
operations to compute these predicates. 
%
Once speculation has been performed on the definition of a variable
used in a \psifun, the predicate associated with this argument
can be promoted, provided that the semantic of the \psifun is maintained (Equation~\ref{eq:psi_ssa:prom}). 



Usually, the first argument of a \psifun can be promoted
under the {true} predicate. Also, when disjoint conditions are
computed, one of them can be promoted to include the other conditions,
usually reducing the number of predicates. A side effect of this
transformation is that it may increase the number of copy instructions
to be generated during the $\psi$-SSA destruction phase,
as will be explained in the following section.


\section{Psi-SSA destruction}
\label{sec:Psi_ssa_destruction}


% Explain what must be done to go out of Psi-SSA. First,
% Psi-normalization must be performed, then live-analysis can be run
% and an interference graph with exact interferences on Psi operations
% can be built. Explain how to repair the interferences and how to
% integrate this algorithm into a standard SSA algorithm.

The SSA destruction\index{SSA!destruction} phase reverts an SSA representation into a non-SSA
representation. This phase must be adapted to the $\psi$-SSA
representation. This algorithm uses
\phipsiwebs to create a conventional $\psi$-SSA
representation. The notion of \phiwebs is \index{phiweb}
extended to $\phi$ and $\psi$ operations so as to derive the notion of
conventional $\psi$-SSA ($\psi$-C-SSA) form\index{C-SSA}. A \phipsiweb is
a non empty, minimal, set of variables such that if two variables are
referenced on the same $\phi$ or \psifun then they are in the
same \phipsiweb. The property of the $\psi$-C-SSA form is that the
renaming into a single variable of all variables that belong to the
same \phipsiweb, and the removal of the $\psi$ and $\phi$
functions, results in a program with the same semantics as the
original program.

% We define the conventional $\psi$-SSA ({\em $\psi$-C-SSA}) form in a
% similar way to the Sreedhar definition of the conventional SSA ({\em
% C-SSA}) form. The $\psi$-SSA web definition is an extension of the
% SSA web to include \psifuns.

Now, consider Figure~\ref{fig:psi_interference} to illustrate the
transformations that must be performed to convert a program from a
$\psi$-SSA form into a program in $\psi$-C-SSA form.

\begin{figure}
\footnotesize
\subfloat[$\psi$-T-SSA form]{
\begin{tabular}{ll}
     ${p?}$  & ${b = ...}$         \\
             & ${a = ...}$         \\
             &                     \\
             & ${x = \psi(a,p?b)}$ \\
\\
\end{tabular}
} \hfill
\subfloat[$\psi$-C-SSA form]{
\begin{tabular}{ll}
${p?}$ & ${b = ...}$         \\
       & ${a = ...}$         \\
${p?}$ & ${c = b}$           \\
       & ${x = \psi(a,p?c)}$ \\
\\
\end{tabular}
} \hfill
\subfloat[non-SSA form]{
\begin{tabular}{lp{2cm}}
${p?}$ & ${b = ...}$ \\
       & ${x = ...}$ \\
${p?}$ & ${x = b}$ \\
       & \\
\\
\end{tabular}
} \hfill
\\
\subfloat[$\psi$-T-SSA\ form]{
\begin{tabular}{ll}
            & ${a = ...}$ \\
            & ${b = ...}$ \\
            &            \\
            & ${x = \psi(a,p?b)}$ \\
\\
\end{tabular}
} \hfill
\subfloat[$\psi$-C-SSA form]{
\begin{tabular}{ll}
            & ${a = ...}$ \\
            & ${b = ...}$ \\
 ${p?}$     & ${c = b}$ \\
            & ${x = \psi(a,p?c)}$ \\
\\
\end{tabular}
} \hfill
\subfloat[non-SSA form]{
\begin{tabular}{lp{2cm}}
            & ${x = ...}$ \\
            & ${b = ...}$ \\
 ${p?}$     & ${x = b}$ \\
            & \\
\\
\end{tabular}
} \hfill
\\
\subfloat[$\psi$-T-SSA form]{
\begin{tabular}{ll}
            & ${a = ...}$ \\
            & \\
${p?}$      & ${b = ...}$ \\
${q?}$      & ${c = ...}$ \\
            & ${x = \psi(a,p?b)}$ \\
            & ${y = \psi(a,q?c)}$ \\
\\
\end{tabular}
} \hfill
\subfloat[$\psi$-C-SSA form]{
\begin{tabular}{ll}
            & ${a = ...}$ \\
            & ${d = a}$ \\
 ${p?}$     & ${b = ...}$ \\
 ${q?}$     & ${c = ...}$ \\
            & ${x = \psi(a,p?b)}$ \\
            & ${y = \psi(d,q?c)}$ \\
\\
\end{tabular}
} \hfill
\subfloat[non-SSA form]{
\begin{tabular}{lp{2cm}}
            & ${x = ...}$ \\
            & ${y = x}$ \\
 ${p?}$ & ${x = ...}$ \\
 ${q?}$ & ${y = ...}$ \\
     & \\
     & \\
\\
\end{tabular}
} \hfill

\caption{Non-conventional $\psi$-SSA ($\psi$-T-SSA)\index{$\psi$-T-SSA} form, $\psi$-C-SSA forms and non-SSA form after destruction}
\label{fig:psi_interference}
\end{figure}

%% <<etendre aussi la projection pour la predication partielle ??
%% (Propagation des predicats a travers les instructions non gardes
%% par un algorithm semblable a la sparse constant propagation) >>

Looking at the first example (Figure~\ref{fig:psi_interference}(a)), the dominance order of the definitions
for the variables \textit{a} and \textit{b} differs from their order from
left to right in the \psifun. Such code may appear after a
code motion algorithm has moved the definitions for \textit{a} and
\textit{b} relatively to each other.
%
Here, the renaming of the variables
\textit{a}, \textit{b} and \textit{x} into a single variable will not restore
the semantics of the original program. The order in which the
definitions of the variables \textit{a}, \textit{b} and \textit{x} occur must
be corrected. This is done through the introduction of the variable
\textit{c} that is defined as a predicated copy of the variable \textit{b}, after the definition of \textit{a}. Now, the renaming of
the variables \textit{a}, \textit{c} and \textit{x} into a single variable will
result in the correct behavior.

In Figure~\ref{fig:psi_interference}(d) the definition of the variable
\textit{b} has been speculated. However, the semantics of the \psifun is that the variable \textit{x} will only be assigned the value
of \textit{b} when \textit{p} is {true}. A new variable \textit{c} must be
defined as a predicated copy of the variable \textit{b}, after the definition of \textit{b} and \textit{p}; in the
\psifun, variable \textit{b} is then replaced by variable \textit{c}. 
The renaming of variables \textit{a}, \textit{c} and \textit{x} into a
single variable will now follow the correct behavior.

In Figure~\ref{fig:psi_interference}(g), the renaming of the variables
\textit{a}, \textit{b}, \textit{c}, \textit{x} and \textit{y} into a single variable
will not give the correct semantics. In fact, the value of \textit{a}
used in the second \psifun would be overridden by the
definition of \textit{b} before the definition of the variable
\textit{c}. Such code will occur after copy folding has been applied on a
$\psi$-SSA representation. We see that the value of \textit{a} has to be
preserved before the definition of \textit{b}. This is done through the definition of a new variable ($d$ here), resulting in the code
given in Figure~\ref{fig:psi_interference}(h). Now, the variables \textit{a},
\textit{b} and \textit{x} can be renamed into a single variable, and the
variables \textit{d}, \textit{c} and \textit{y} will be renamed into another
variable, resulting in a program in a non-SSA form with the correct
behavior.

We will now present an algorithm that will transform a program from a
$\psi$-SSA form into its $\psi$-C-SSA form. This algorithm is made of
three parts.

\begin{itemize}
\item \emph{Psi-normalize}~: This phase puts all \psifuns \index{normalized-$\psi$}
in what we call a {\em normalized} form.
\item \emph{Psi-web}~: \index{\psiweb}This phase grows \psiwebs from \psifuns, and introduces repair code where needed such that each \psiweb is interference free.
\item \emph{Phi-web}~: This phase is the standard SSA-destruction algorithm (e.g., see Chapter~\ref{chapter:alternative_ssa_destruction_algorithm}) with the additional constraint that all variables in a \psiweb must be coalesced together. This can be done using the pining\index{pining}\index{coalescing} mechanism presented in Chapter~\ref{chapter:alternative_ssa_destruction_algorithm}. 
\end{itemize}

We detail now the implementation of each of the first two parts.

\subsection{Psi-normalize}

We define the notion of {\em normalized}-$\psi$.\index{normalized-$\psi$} The normalized form of a \psifun has two characteristics:

\begin{itemize}
\item The order of the arguments in a normalized-\psifun is,
from left to right, equal to the order of their definitions, from top
to bottom, in the control flow dominance tree.
\item The predicate associated with each argument in a
normalized-\psifun is equal to the predicate used on the
unique definition of this argument.
\end{itemize}

These two characteristics correspond respectively to the two cases
presented in Figure~\ref{fig:psi_interference}(a) and
Figure~\ref{fig:psi_interference}(d).
When some arguments of a \psifun are also defined by \psifuns, the {normalized}-$\psi$ characteristics must hold on a
virtual \psifun where $\psi$-inlining has been performed on
these arguments.

When \psifuns
are created during the construction of the $\psi$-SSA representation,
they are naturally built in their normalized form. Later, \index{$\psi$-T-SSA}
transformations are applied to the $\psi$-SSA representation.
Predicated definitions may be moved relatively to each others. Also,
operation speculation and copy folding may enlarge the domain of the
predicate used on the definition of a variable. These transformations
may cause some \psifuns to be in a non-normalized form.




%\SubSubSection{PSI-normalize implementation}
\paragraph{PSI-normalize implementation}

Each \psifun is processed independently. An analysis of the
\psifuns in a top down traversal of the dominator tree
reduces the amount of repair code that is inserted during this pass. We
only detail the algorithm for such a traversal.

For a \psifun ${a_0 = \psi(p_1?a_1,\ \dots,\ p_i?a_i,\ \dots,\
  p_n?a_n)}$, the argument list is processed from left to right. For
each argument ${a_i}$, the predicate ${p_i}$ associated with this argument
in the \psifun and the predicate used on the definition of
this argument are compared. If they are not equal, a new variable
${a'_i}$ is introduced and is initialized at the highest point in the
dominator tree after the definition of ${a_i}$ and ${p_i}$. ${a'_i}$ is
defined by the operation ${p_i\cond a'_i = a_i}$. Then, ${a_i}$ is
replaced by ${a'_i}$ in the \psifun.

Then, we consider the dominance order of the definition for ${a_i}$,
with the definition for ${a_{i-1}}$. When ${a_i}$ is defined on a
\psifun, we recursively look for the definition of the first
argument of this \psifun, until a definition on a non-\psifun is found. 
If the definition we found for ${a_i}$
dominates the definition for ${a_{i-1}}$, some correction is needed.
%
If the predicates ${p_{i-1}}$ and ${p_i}$ are disjoint, a
$\psi$-permutation can be applied between ${a_{i-1}}$ and
${a_i}$, so as to reflect into the \psifun the actual
dominance order of the definitions of ${a_{i-1}}$ and ${a_i}$.
%
If $\psi$-permutation cannot be applied, a new variable ${a'_i}$
is created for repair. ${a'_i}$ is defined by the operation
${p_i? a'_i = a_i}$. This copy operation is inserted at the highest
point that is dominated by the definitions of ${a_{i-1}}$ and
${a_i}$.
\footnote{When ${a_i}$ is defined by a \psifun, its
  definition may appear after the definition for ${a_{i-1}}$,
  although the non-$\psi$ definition for ${a_i}$ appears before
  the definition for ${a_{i-1}}$.}
Then, ${a_i}$ is replaced in the \psifun by ${a'_i}$.

The algorithm continues with the argument ${a_{i+1}}$, until all
arguments of the \psifun are processed. When all arguments
are processed, the $\psi$ is in its normalized form. When all $\psi$
functions are processed, the function will contain only
normalized-\psifuns.

%% The top-down traversal of the dominator tree will ensure that when a
%% variable in a \psifun is defined by another \psifun,
%% this \psifun has already been analyzed and put in its
%% normalized form. Thus the definition of its first variable already
%% dominates the definitions for the other arguments of the $\psi$
%% function.

\subsection{Psi-web}
\index{\psiweb}
The role of the psi-web phase is to repair the \psifuns that are part of a non interference-free \psiweb. \index{interference}
This case corresponds to the example presented in
Figure~\ref{fig:psi_interference}(g).
%
In the same way as there is a specific point of use for arguments on\index{uses, of \psifuns}
\phifuns for liveness analysis (e.g., see Section~\ref{sec:alternative_ssa_destruction_algorithm:liveness}), we give a definition of the
actual point of use of arguments on normalized \psifuns for liveness
analysis. With this definition, liveness\index{liveness} analysis is computed
accurately and an interference graph can be built. The cases where repair code is needed can be easily and
accurately detected by observing that variables in a
\psifun interfere.

%\SubSubSection{Liveness and interferences in Psi-SSA}
\paragraph{Liveness and interferences in Psi-SSA.}
Consider the code in Figure~\ref{fig:psi_ccond} (b). Instead of using
a representation with \psifuns, predicated definitions have
been modified to make a reference to the value the predicated
definition will have in case the predicate evaluates to false. We use in this
example the notation of the select operator
$x = \textit{cond}\cond \textit{exp1}~:~\textit{exp2}$ that assigns \textit{exp1} to $x$ if \textit{cond} is true and \textit{exp2} otherwise. 
Each of the predicated definitions make an
explicit use of the variable immediately to its left in the argument
list of the original \psifun from Figure~\ref{fig:psi_ccond}
(a). We can see that a renaming of the variables \textit{a}, \textit{b},
\textit{c} and \textit{x} into a single representative name will still
compute the same value for the variable \textit{x}. Note that this
transformation can only be performed on normalized \psifuns,
since the definition of an argument must be dominated by the
definition of the argument immediately at its left in the argument
list of the \psifun, and the same predicate must be used on the
 definition of an argument and with this argument in the $\psi$ operation.
Using this equivalence for the
representation of a \psifun, we now give a definition of the
point of use for the arguments of a \psifun.

\begin{definition}[use points]\index{uses, of \psifuns} Let ${a_0 = \psi(p_1?a_1, ..., p_i?a_i, ...,
  p_n?a_n)}$ be a normalized \psifun. For $i<n$, the point of use of argument $a_i$ occurs at the operation that defines $a_{i+1}$. The point of use
  for the last argument $a_n$ occurs at the \psifun itself.
\end{definition}

\begin{figure}
\begin{center}
\footnotesize\hfill
\subfloat[$\psi$-SSA form]{
\begin{tabular}{ll}
           & ${a = \texttt{op}1}$ \\
${p?}$ & ${b = \texttt{op}2}$  \\
${q?}$ & ${c = \texttt{op}3}$\\
           & ${x = \psi(a,\ p?b,\ q?c)}$  \\
\\
\end{tabular}}
\hfill
\subfloat[conditional form]{
\begin{tabular}{p{2.5cm}}
${a = \texttt{op}1}$ \\
${b = p\ ?\ \texttt{op}2\ :\ a}$ \\
${c = q\ ?\ \texttt{op}3\ :\ b}$ \\
${x = c}$ \\
\\
\end{tabular}
}
\caption{\psifuns and C conditional operations equivalence}
\label{fig:psi_ccond}
\end{center}
\end{figure}

Given this definition of point of use of \psifun arguments, and using
the usual point of use of \phifun arguments, a traditional liveness
analysis can be run. Then an interference graph can be built to
collect the interferences between variables involved in $\psi$ or
\phifuns. For the construction of the interference graph, an
interference between two variables that are defined on disjoint
predicates can be ignored.

%\SubSubSection{Repairing interferences on $\psi$ operations}
\paragraph{Repairing interferences on \psifuns.}
We now present an algorithm that resolves the interferences as it builds the \psiwebs. A \index{interference}\index{\psiweb}
pseudo-code of this algorithm is given in
Figure~\ref{fig:pseudo_psi_repair}.
First, the \psiwebs are initialized with a single variable per \psiweb. Then,
\psifuns are processed one at a time, in no specific order, merging when non-interfering the \psiwebs of its operands together.
Two \psiwebs interfere if at least one variable in
the first \psiweb interferes with at least one variable in the
other one.
The arguments of the \psifun, say ${a_0 = \psi(p_1?a_1, ..., p_i?a_i, ...,
  p_n?a_n)}$, are processed
from right ($a_n$) to left ($a_1$). If the \psiweb that contains $a_i$ does not interfere with the \psiweb that contains $a_0$, they are merged together.
Otherwise, repair code is
needed. A new variable, ${a'_i}$, is created and is initialized
with a predicated copy ${p_i\cond a'_i = a_i}$, inserted just above
the definition for ${a_{i+1}}$, or just above the \psifun in case of the last argument. The current argument ${a_i}$ in
the \psifun is replaced by the new variable ${a'_i}$. The
interference graph is updated. This can be done by considering the set of variables, say $U$, $a_i$ interferes with. For each $u\in U$, if $u$ is in the merged \psiweb, it should not interfere with $a'_i$; if the definition of $u$ dominates the definition of $a_i$, it is live-through the definition of $a_i$, thus is should be made interfering with $a'_i$; last, if the definition of $a_i$ dominates the definition of $b$, it should be made interfering only if this definition is within the live-range\index{live-range}\index{liveness check} of $a'_i$ (see Chapter~\ref{chapter:ssa_tells_nothing_of_liveness}).

{
\def\psiWeb{\textit{psiWeb}\xspace}
\def\opndWeb{\textit{opndWeb}\xspace}
\begin{algorithm}[h]
\Begin{
 \Let{\psiWeb be the web containing $a_0$} \; 
 \ForEach{$a_i$ \textbf{in} $[a_n,\ a_{n-1},\ \dots, a_1]$}{
   \Let{\opndWeb be the web containing $a_i$} \;
   \If{$\opndWeb \neq \psiWeb$}{
      \If{\textit{IGraph}.\textsf{interfere}(\psiWeb, \opndWeb)}{
         \Let{$a'_i$ be a freshly created variable} \;
         \Let{$C_i$ be a new predicated copy $p_i\cond a'_i\gets a_i$} \;
         \Let{\textit{op} be the operation that defines $a_{i+1}$, $a_i.\textit{def.op}$}, or the psi operation \;
         \While{\textit{op} is a \psifun}{
             replace \textit{op} by the operation that defines its first argument \;
         }
         append $C_i$ right before \textit{op} \;
         replace $a_i$ by $a'_i$ in the \psifun \;
         $\opndWeb \gets \{a'_i\}$ \;
         \ForEach{$u$ \textbf{in} $\textit{IGraph}.\textsf{interferenceSet}(a_i)$}{
            \If{$u \not\in\psiWeb$}{
              \If{$u.\textit{def.op} \textsf{ dominates }  a_i.\textit{def.op} \bigvee a'_i \in \textsf{livein}(u.\textit{def.op})$}{ 
                \textit{IGraph}.\textsf{addInterference}($a'_i, a$) \;
              } }
         }
       }
       $\psiWeb \gets \psiWeb \cup \opndWeb$\;
   }
 }
}
\caption{\psiwebs merging during the processing of a \psifun ${a_0 = \psi(p_1?a_1, ..., p_i?a_i, ...,
  p_n?a_n)}$}
\label{fig:pseudo_psi_repair}
\end{algorithm}


% Some comments on an exact interference graph update ??

Consider the code in Figure~\ref{fig:live_interference} to see how
this algorithm works. The liveness on the \psifun creates a
live-range for variable \textit{a} that extends down to the definition of
\textit{b}, but not further down. Thus, the variable \textit{a} does not
interfere with the variables \textit{b}, \textit{c} or \textit{x}. The
live-range for variable \textit{b} extends down to its use in the
definition of variable \textit{d}. This live-range interferes with the
variables \textit{c} and \textit{x}. The live-range for variable \textit{c}
extends down to its use in the \psifun that defines the
variable \textit{x}.
%
At the beginning of the processing on the \psifun ${x =
  \psi(p?a,q?b,r?c)}$, \psiwebs are singletons $\{a\},\ \{b\},\ \{c\},\ \{x\},\ \{d\}$. The argument list is processed from right
to left i.e., starting with variable $c$. $\{c\}$ does not interfere with $\{x\}$, they can be merged together, resulting in 
$\psiWeb=\{x, c\}$. Then, variable \textit{b} is
processed. Since it interferes with both \textit{x} and \textit{c},
repairing code is needed. A variable \textit{b'} is created, and is
initialized just below the definition for \textit{b}, as a predicated
copy of \textit{b}. The interference graph is updated conservatively, with no changes. \psiWeb now becomes ${\{x, b', c\}}$. Then variable \textit{a}
 is processed, and as no interference is encountered, $\{a\}$ is merged to \psiWeb. The
final code after SSA destruction is shown in
Figure~\ref{fig:live_interference}(c).
}
\begin{figure}
\begin{center}
\footnotesize
\hfill
\subfloat[before processing the \psifun]{
\begin{tabular}{ll}
${p?}$ & ${a = ...}$       \\
${q?}$ & ${b = ...}$      \\
           &               \\
${r?}$ & ${c = ...}$         \\
           & ${x = \psi(p?a,q?b,r?c)}$ \\
${s?}$ & ${d = b+1}$          \\
\\
\end{tabular}}
\hfill
\subfloat[after processing the \psifun]{
\begin{tabular}{ll}
    ${p?}$ & ${a = ...}$   \\
    ${q?}$ & ${b = ...}$  \\
    ${q?}$ & ${b' = b}$    \\
    ${r?}$ & ${c = ...}$    \\
   & ${x = \psi(p?a,q?b',r?c)}$ \\
    ${s?}$ & ${d = b+1}$  \\
\\
\end{tabular}
}
\hfill
\subfloat[after actual coalescing]{
\hspace{1cm}\begin{tabular}{lp{2cm}}
 ${p?}$ & ${x = ...}$\\
 ${q?}$ & ${b = ...}$\\
  ${q?}$ & ${x = b}$\\
  ${r?}$ & ${x = ...}$ \\
\\
${s?}$ & ${d = b+1}$ \\
\\
\end{tabular}
}
\caption{Elimination of $\psi$ live-interference}
\label{fig:live_interference}
\end{center}
\end{figure}


\section{Additional reading}

In this chapter we mainly described the $\psi$-SSA representation and we detailed specific transformations that can be performed thanks to this representation. More details on the implementation of the $\psi$-SSA algorithms, and figures on the benefits of this representation, can be found in \cite{Stoutchinin:2001:MICRO} and \cite{Ferriere:2007:SCOPES}.

We mentioned in this chapter that a number of classical SSA-based algorithm can be easily adapted to the $\psi$-SSA representation, usually by just adapting the rules on the \phifuns to the \psifuns. Among these algorithm, we can mention the constant propagation algorithm described in~\cite{WZ91}, dead code elimination~\cite{morgan98}, global value numbering~\cite{Cli95}, partial redundancy elimination~\cite{CCK+97} and induction variable analysis~\cite{Wolfe92} which have already been implemented into a $\psi$-SSA framework.

There are also other SSA representations that can handle predicated instruction, of which is the Predicated SSA representation~\cite{Carter:PACT99}. This representation is targeted at very low level optimization to improve operation scheduling in presence of predicated instructions. Another representation is the Gated SSA form, presented in Chapter~\ref{chapter:vsdg}.

The $\psi$-SSA destruction algorithm presented in this chapter is inspired from the SSA destruction algorithm of Sreedhar et al.~\cite{SreedharSep99} that introduces repair code when needed as it grows \phiwebs from \phifuns. The phi-web phase mentioned in this chapter to complete the $\psi$-SSA destruction algorithm can use exactly the same approach by simply initializing \phipsiwebs by \psiwebs.
