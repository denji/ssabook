\REM{
\begin{figure}
{\small
{\bf Input:} Intermediate code for method being optimized, augmented
with the $\DS$ and $\DD$ relations defined in Section~\ref{svalnum}.

\vspace{14pt}

{\bf Output:} Transformed intermediate code after performing scalar
replacement.

\vspace{14pt}

{\bf Algorithm:}
\begin{enumerate}

\item \label{item:arrayssa}
{\bf Build extended Array SSA form for each heap array.}

Build Array SSA form, inserting control $\phi$,
$d\phi$ and $u\phi$ functions as outlined in Section~\ref{model},
and renaming of all heap array definitions and uses.

As part of this step, we annotate each call instruction with dummy
defs and uses of each heap array for which a def or a use can reach the call
instruction.  
If interprocedural analysis is possible, the call
instruction's heap array defs and uses can
be derived from a simple flow-insensitive
summary of the called method.  

\item \label{item:dflow}
{\bf Perform index propagation.}
\begin{enumerate}
\item Walk through the extended Array SSA intermediate representation,
and for each $\phi$, $d\phi$, or $u\phi$ statement, create a 
dataflow equation with the appropriate operator as listed in 
Figures~\ref{fig:scalrep-dphi},~\ref{fig:scalrep-uphi}~or~\ref{fig:scalrep-join}.
\item Solve the system of dataflow equations by iterating to a fixed point.
\end{enumerate}
After index propagation, the lattice value of each 
heap array, $A_i$,
is 
$\L(A_i) = \{\; \V(\vec{k}) \; | \;
\mbox{location $A[\vec{k}]$ is ``available'' at def $A_i$ (and all uses of $A_i$)} \; \}$.

\item \label{item:analysis}
{\bf Scalar replacement analysis.}

\begin{enumerate}
\item Compute $\URS = \{\; \mbox{use $A_j[\vec{x}]$} \; | \; \exists\; \V(\vec{x}) \; \in \; \L(A_j)\;\}$ \ie\
use $A_j[\vec{x}]$ is placed in \URS\ if and only if location $A[\vec{x}]$ is available
at the def of $A_j$ and hence at the use of $A_j[\vec{x}]$.
(Note that $A_j$ uniquely identifies a use, since all uses are renamed in
extended Array SSA form.)

\item Compute $\DRS = \{\;  \mbox{def $A_i[\vec{k}]$} \; | \; \exists \; \mbox{use $A_j[\vec{x}] \in \URS$ with $\V(\vec{x})=\V(\vec{k})$} \; \}$ \ie\ def  $A_i[\vec{k}]$ is placed in \DRS\ 
if and only if a use $A_j[\vec{x}]$ was placed in \URS\ with  $\V(\vec{x})=\V(\vec{k})$.
\end{enumerate}

\item \label{item:transform}
{\bf Scalar replacement transformation.}

Apply scalar replacement actions selected in step~\ref{item:analysis}
above
to the {\it original} program and
obtain the transformed program.

\end{enumerate}
}
\caption{Overview of Redundant Load Elimination algorithm.}
\label{fig:overview}
\end{figure}
}
\REM{
\begin{figure}
{\small
{\bf Input:} Data-flow equations for the extended Array SSA form of
the input method.

{\bf Outputs:}
Scalar replacement actions defined by the following sets:
\begin{enumerate}
\item \DRS\ = set of non-$\phi$ array defs selected for scalar replacement. 
 
For each def $A_i \in \DRS$,
the def
statement $A_i[\vec{k}] := \mbox{\sc rhs}$ in the original program should be replaced by
two statements, $\At_n := \mbox{\sc rhs} ;  A_i[\vec{k}] := \At_n$,
where $n=\V(\vec{k})$ is the value number for index expression $\vec{k}$.
%(The $\At_n := \mbox{\sc rhs}$ statement will usually be optimized away
%by copy propagation.)

\item \URS\ = set of non-$\phi$ array uses (loads) selected for scalar replacement.  

For each use $A_j \in \URS$, the use
statement $\mbox{\sc lhs} := A_j[\vec{x}]$ in the original program should be replaced by the
statement, $\mbox{\sc lhs} := \At_n$,
where $n=\V(\vec{x})$ is the value number for index expression $\vec{x}$.
%The $\mbox{\sc lhs} := \At_n$ statement will also usually be optimized away
%by copy propagation.
\end{enumerate}
\REM{
In the above scalar replacement actions, $\At_n$ represents
a single
scalar temporary created for all references to array $A$ in the
original program for which the index expression has value number = $n$.
}

{\bf Algorithm:}
\begin{enumerate}
\item Initialization:
\begin{enumerate}
\item Initialize the lattice value for each dummy heap array definition
$\H_0$ inserted in the start block
to $\L(\H_0) = \bot$.  
Also, insert into {\it worklist} all  equations $E$
that contain $\L(\H_0)$ in their RHS.

\item Initialize the lattice value for all other heap arrays 
$\H_i$ to $\L(\H_i) = \top$.
\end{enumerate}

\item Index propagation (fixpoint iteration):
\begin{programa}
\Ta {\bf while} ( {\it worklist} is not empty ) \{ \\
\Tb $E :=$ remove any equation from {\it worklist}\\
\Tb Recompute $\L(v)$, the LHS of equation $E$, based on the values of $E$'s RHS terms\\
\Tb {\bf if} ( LHS of equation $E$ has changed ) \{ \\
\Tc {\bf for each} ( equation $E'$ that uses $\L(v)$ in its RHS ) \{ \\
\Td Insert equation $E'$ into {\it worklist}\\
\Tc \} \\
\Tb \} \\
\Ta \} \\
\end{programa}
After index propagation, the lattice value of each ($\phi$ or non-$\phi$) definition, $A_i$,
is 
$\L(A_i) = \{\; \V(\vec{k}) \; | \;
\mbox{location $A[\vec{k}]$ is ``available'' at def $A_i$ (and all uses of $A_i$)} \; \}$.

\item Compute $\URS = \{\; \mbox{use $A_j[\vec{x}]$} \; | \; \exists\; \V(\vec{x}) \; \in \; \L(A_j)\;\}$ \ie\
use $A_j[\vec{x}]$ is placed in \URS\ if and only if location $A[\vec{x}]$ is available
at the def of $A_j$ and hence at the use of $A_j[\vec{x}]$.
(Note that $A_j$ uniquely identifies a use, since all uses are renamed in
extended Array SSA form.)

\REM{
Note that since the program is in Array SSA form, there is a single
definition of $A_j$ and a single definition of $\vec{x}$, both of which must
dominate the use $A_j[\vec{x}]$ (which is a use of $A_j$ and a use of $\vec{x}$).
Also, $\vec{x}$ must have the same value number as the index of the assignment
that propagated $\V(\vec{x})$ into $\L(A_j)$.
}

\REM{
{\it Vivek: doesn't the above need to be justified wrt a modification to A and an modification to x between the def and the use. its true but it needs a reason.}
}

\item Compute $\DRS = \{\;  \mbox{def $A_i[\vec{k}]$} \; | \; \exists \; \mbox{use $A_j[\vec{x}] \in \URS$ with $\V(\vec{x})=\V(\vec{k})$} \; \}$ \ie\ def  $A_i[\vec{k}]$ is placed in \DRS\ 
if and only if a use $A_j[\vec{x}]$ was placed in \URS\ with  $\V(\vec{x})=\V(\vec{k})$.
\end{enumerate}
}
\caption{Algorithm for scalar replacement analysis for redundant load elimination.}
\label{alg:load}
\end{figure}
}


\begin{figure}%[htbp]
\begin{center}
\begin{tabular}{|l||c|c|c|}
\hline
$\L(A_2)$ & $\L(A_0) = \top$ & $\L(A_0) = \langle \vec{i_1}, \ldots \rangle $ & $\L(A_0) = \bot$ \\
\hline \hline
$\L(A_1) = \top$ & $\top$ & $\top$ & $\top$ \\
\hline
$\L(A_1) = \langle \vec{i'}\rangle$ & $\top$ &
$\Update(\vec{i'},\langle (\vec{i_1}), \ldots \rangle)$ & $\langle
\vec{i'} \rangle$ \\
\hline
$\L(A_1) = \bot$ & $\bot$ & $\bot$ & $\bot$ \\
\hline
\end{tabular}
\end{center}
\caption{Lattice computation for \protect{$\L(A_2)  =  \L_{d\phi}(\L(A_1), \L(A_0))$}
where $A_2 := d\phi(A_1, A_0)$ is
a definition $\phi$ operation}
\label{fig:scalrep-dphi}
\end{figure}

\begin{figure}%[htbp]
\begin{center}
\begin{tabular}{|l||c|c|c|}
\hline
$\L(A_2)$ & $\L(A_0) = \top$ & $\L(A_0) = \langle (\vec{i_1}), \ldots \rangle $ & $\L(A_0) = \bot$ \\
\hline \hline
$\L(A_1) = \top$ & $\top$ & $\top$ & $\top$ \\
\hline
$\L(A_1) = \langle \vec{i'} \rangle$ & $\top$ & $ \L(A_1) \cup \L(A_0)$ & $ \L(A_1)$ \\
\hline
$\L(A_1) = \bot$ & $\bot$ & $\bot$ & $\bot$ \\
\hline
\end{tabular}
\end{center}
\caption{Lattice computation for \protect{$\L(A_2)  =  \L_{u\phi}(\L(A_1), \L(A_0))$}
where $A_2 := u\phi(A_1, A_0)$ is
a use $\phi$ operation}
\label{fig:scalrep-uphi}
\end{figure}


\begin{figure}%[htbp]
\begin{center}
\begin{tabular}{|l||c|c|c|}
\hline
$\L(A_2) = \L(A_1) \sqcap \L(A_0) $ & $\L(A_0) = \top$ & $\L(A_0) = \langle (\vec{i_1}), \ldots \rangle $ & $\L(A_0) = \bot$ \\
\hline \hline
$\L(A_1) = \top$ & $\top$ & $\L(A_0)$ & $\bot$ \\
\hline
$\L(A_1) = \langle \vec{i'_1}, \ldots\rangle$ & $\L(A_1)$ & $\L(A_1) \cap \L(A_0)$ & $\bot$ \\
\hline
$\L(A_1) = \bot$ & $\bot$ & $\bot$ & $\bot$ \\
\hline
\end{tabular}
\end{center}
\caption{Lattice computation for 
$\L(A_2) = \L_{\phi}(\L(A_1), \L(A_0)) = \L(A_1) \sqcap \L(A_0) $,
where $A_2 := \phi(A_1, A_0)$ is
a control $\phi$ operation}
\label{fig:scalrep-join}
\end{figure}

\begin{figure}
\begin{tabular}[t]{|c|c|c|}
\hline
\begin{minipage}[t]{1.5in}
(a) Extended Array SSA form: 
\begin{programa}
r := p\\
q := new Type1\\
. . .\\
$\H^x_1[p]$ := ...\\
$\H^x_2$ := $d\phi(\H^x_1, \H^x_0)$\\
$\H^x_3[q]$ := ...\\
$\H^x_4$ := $d\phi(\H^x_3, \H^x_2)$\\
... := $\H^x_4[r]$
\end{programa}
\end{minipage}
&
\begin{minipage}[t]{1.5in}
(b) After index propagation:
\begin{eqnarray*}
\L(\H^x_0) & = & \{ \; \} \\
\L(\H^x_1) & = & \{ \V(p)=\V(r) \} \\
\L(\H^x_2) & = & \{ \V(p)=\V(r) \} \\
\L(\H^x_3) & = & \{ \V(q) \} \\
\L(\H^x_4) & = & \{ \V(p) =\V(r), \V(q) \} 
\end{eqnarray*}
\end{minipage}
&
\begin{minipage}[t]{1.5in}
(c) After transformation:
\begin{programa}
r := p\\
q := new Type1\\
. . .\\
T1 := ...\\
p.x := T1\\
q.x := ...\\

... := T1
\end{programa} 
\end{minipage}
\\
\hline
\end{tabular}
\caption{Trace of index propagation and load elimination transformation for program in figure \protect{\ref{fig:ex2}}(a)}
\label{fig:ex2a:trace}
\end{figure}

The main program analysis needed to enable redundant load elimination
is {\it index propagation},
which identifies the set of indices that
are {\em available} at a specific def/use  $A_i$ of heap array $A$.
Index propagation is a dataflow problem, the goal of which is to compute a lattice value
$\L(\H)$ for each renamed heap variable $\H$ in the Array SSA form such that a load of $\H[\vec{i}]$ is {\em available}
if $\V(\vec{i}) \in \L(\H)$.  Note that the lattice element does not include the value of $\H[\vec{i}]$ (as in constant propagation), just the fact that it is available.
Figures~\ref{fig:scalrep-dphi},~\ref{fig:scalrep-uphi}~and~\ref{fig:scalrep-join} give the lattice computations which define the index propagation solution.
The notation 
$\Update(\vec{i'},\langle \vec{i_1}, \ldots \rangle)$
used in the middle cell in 
figure~\ref{fig:scalrep-dphi} denotes a special update of 
the list $\L(A_0) = \langle \vec{i_1}, \ldots \rangle$
with respect to index $\vec{i'}$.
$\Update$ involves four steps:
\begin{enumerate}
\item Compute the list $T = \{\;\vec{i_j}\;|\;\vec{i_j}\in\L(A_0)
\mbox{~and~}\DD(\vec{i'},\vec{i_j})=\mbox{\it true}\;\}$.  List $T$
contains only those indices from $\L(A_0)$ that are
{\it definitely different} from $\vec{i'}$.

\item Insert $\vec{i'}$ into $T$ to obtain a new list, $I$.
\item (Optional) As before, if there is a desire to bound the height of the lattice due to
  compile-time considerations, and the
  size of list
$I$ exceeds a threshold size $Z$, then any one of the indices in $I$ can
be 
dropped from the output list.
\item Return $I$ as the value of 
$\Update(\vec{i'},\langle \vec{i_1}, \ldots \rangle)$.
\end{enumerate}

\REM{
The lattice computations for arrays are similar.  Since an $n$-dimensional
array is represented by an $n+1$-dimensional Heap variable, the 
index corresponding to an array load or store is an $n+1$-tuple.
For example, consider a Heap variable $A$ representing a one-dimensional
Java array.  Then $A$ is a two-dimensional array, and
an {\em index} into $A$ is a pair $< $p$, $v$>$, representing the
def or use of array element written as {\tt p[v]} (note that {\tt p}
is a pointer, and must be analyzed as such).
The index propagation solution
for $A$ will be a set of value number pairs $S$, such that 
we know $A[<p,x>]$ is available if $\exists <v,w> \in S s.t. DS(V(p),v) 
\wedge DS(V(x),w)$.
}

\REM{
{\it TODO: explain that Figure~\ref{fig:scalrep-dphi} is used for a
WRITE of a heap array, and a simple pass-through copy  operation is
used for a READ of a heap array.}
}

After index propagation, the algorithm selects a load,
$A_j[\vec{x}]$, for scalar replacement if and only if index propagation
determines that an index with value number $\V(\vec{x})$ is available at the 
def of $A_j$.
% If so, the use is included in the set of uses selected
% for scalar replacement.
% Finally, an array def, $A_i[\vec{k}]$, is selected for
% scalar replacement if and only if some use $A_j[\vec{x}]$ was placed in \URS\ such
% that  $\V(\vec{x})=\V(\vec{k})$.  
% All such defs are included in \DRS\, the set of defs selected for scalar
% replacement.
Figure~\ref{fig:ex2a:trace} illustrates a trace of this load
elimination algorithm for the example program in
figure~\ref{fig:ex2}(a).  Figure~\ref{fig:ex2a:trace}(a) shows the
extended Array SSA form computed for this example program.  The results
of index propagation are shown in figure~\ref{fig:ex2a:trace}(b).
These results depend on \dd\ analysis establishing that $\V(p) \not=
\V(q)$ and \ds\ analysis establishing that $\V(p) = \V(r)$.
Figure~\ref{fig:ex2a:trace}(c) shows the transformed code after
performing the scalar replacement actions.  The load of {\tt p.x}
has thus
been eliminated in the transformed code, and replaced by a use
of the scalar temporary, {\tt T1}.

% We conclude this section with a brief discussion of the impact of
% the Java Memory Model (JMM).
% It has been observed that redundant load elimination
% can be an illegal
% transformation for multithreaded programs with data races written for a
% memory model, such as the JMM,
% that includes the memory coherence
% assumption. 
% If necessary, our algorithms can be modified to 
% obey memory coherence by simply treating each $u\phi$ function 
% as a $d\phi$ function \ie\ by treating each array use also as an array def.
