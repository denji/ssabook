Static single assignment (SSA) form for scalars has been a significant
advance. It has simplified the way we think about scalar variables.
It has simplified the design of some optimizations and has made other
optimizations more effective. A direct application of classical SSA form to
arrays, would 
view an array as a single object.  But the kinds of analyses that
sophisticated compilers need to perform on
arrays, for example those that drive loop parallelization, are at the
element level.  
In this chapter, we introduced an Array SSA form that captures precise
element-level data flow information for array variables. It is general and simple, and coincides with standard SSA form
when applied to scalar variables.  It can also be used for structures
and other variable types that can be modeled as arrays.  
We presented efficient algorithms based on Array SSA form that perform
constant propagation and
conditional constant propagation through both
scalar and array references.
These algorithms use an extension of the classical constant
propagation lattice so that it can efficiently record information
about array elements.  
The original sparse conditional constant propagation algorithm in
\cite{WeZa91} dealt with control flow and data flow separately by
maintaining two distinct work lists.  The algorithm presented in this chapter
is conceptually simpler because it uses a single set
of data flow equations instead. 

We also presented a unified framework to analyze
object-field and array-element references for programs written in
strongly-typed languages such as Java and Modula-3.  Our solution
models object references as heap
arrays, and uses global value numbering and allocation site
information to determine if two object references are known to be same
or different.  We presented algorithms to identify fully redundant
loads and dead stores, based on sparse propagation in an extended Array SSA
form.

There are many possible directions for future research based on this work.
One direction is to extend the value numbering and 
definitely-different analyses mentioned in section~\ref{sec:non-const}
so that they can be combined with conditional constant propagation
rather than performed as a pre-pass.
Further, it would be interesting 
to gain an understanding of when
adding lattice elements for @ variables could lead to 
extra precision in program analysis 
compared to using executable flags.
An ultimate goal is
to combine conditional constant and type propagation, value numbering, partial redundancy elimination,
and scalar replacement analyses with a single framework that can
analyze heap accesses as effectively as scalar operations.
